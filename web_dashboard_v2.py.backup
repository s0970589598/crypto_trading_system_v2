#!/usr/bin/env python3
"""
äº¤æ˜“ç³»çµ± Web Dashboard v2
æŒ‰ç…§ç³»çµ±å®Œæ•´åŠŸèƒ½æ¸…å–®çš„ 10 å¤§é¡åˆ¥çµ„ç¹”
"""

import streamlit as st
import pandas as pd
import json
import glob
from datetime import datetime
from pathlib import Path
import plotly.graph_objects as go
import plotly.express as px
import sys
sys.path.insert(0, '.')

# è¨­ç½®é é¢é…ç½®
st.set_page_config(
    page_title="äº¤æ˜“ç³»çµ± Dashboard v2",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ¨™é¡Œ
st.title("ğŸš€ å¤šç­–ç•¥äº¤æ˜“ç³»çµ± Dashboard v2")

# å´é‚Šæ¬„ - æŒ‰ç…§ 10 å¤§åŠŸèƒ½åˆ†é¡
st.sidebar.title("ğŸ“‹ ç³»çµ±åŠŸèƒ½")

# ä¸»åˆ†é¡
category = st.sidebar.radio(
    "é¸æ“‡åŠŸèƒ½é¡åˆ¥",
    [
        "1ï¸âƒ£ å›æ¸¬ç³»çµ±",
        "2ï¸âƒ£ å¯¦ç›¤äº¤æ˜“", 
        "3ï¸âƒ£ åƒæ•¸å„ªåŒ–",
        "4ï¸âƒ£ è™§æåˆ†æ",
        "5ï¸âƒ£ æ€§èƒ½ç›£æ§",
        "6ï¸âƒ£ äº¤æ˜“è¦†ç›¤",
        "7ï¸âƒ£ ç­–ç•¥ç®¡ç†",
        "8ï¸âƒ£ é¢¨éšªç®¡ç†",
        "9ï¸âƒ£ æ•¸æ“šç®¡ç†",
        "ğŸ”Ÿ ç³»çµ±é…ç½®"
    ]
)

# ==================== 1. å›æ¸¬ç³»çµ± ====================
if category == "1ï¸âƒ£ å›æ¸¬ç³»çµ±":
    st.header("ğŸ“Š å›æ¸¬ç³»çµ±")
    
    # å­åŠŸèƒ½é¸æ“‡
    sub_function = st.sidebar.selectbox(
        "é¸æ“‡åŠŸèƒ½",
        [
            "å–®ç­–ç•¥å›æ¸¬çµæœ",
            "å¤šç­–ç•¥çµ„åˆå›æ¸¬",
            "æ§“æ¡¿å°æ¯”æ¸¬è©¦",
            "å€‰ä½å°æ¯”æ¸¬è©¦",
            "ç¸¾æ•ˆæŒ‡æ¨™åˆ†æ",
            "äº¤æ˜“æ˜ç´°æŸ¥çœ‹"
        ]
    )
    
    if sub_function == "äº¤æ˜“æ˜ç´°æŸ¥çœ‹":
        st.subheader("ğŸ“‹ äº¤æ˜“æ˜ç´°æŸ¥çœ‹")
        
        # æŸ¥æ‰¾æ‰€æœ‰å›æ¸¬çµæœ
        result_files = glob.glob('backtest_result_*.json')
        
        if not result_files:
            st.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°å›æ¸¬çµæœæ–‡ä»¶")
            st.info("è«‹å…ˆé‹è¡Œå›æ¸¬ï¼š`python3 backtest_multi_timeframe.py`")
        else:
            # é¸æ“‡å›æ¸¬çµæœ
            selected_file = st.selectbox(
                "é¸æ“‡å›æ¸¬çµæœ",
                result_files,
                format_func=lambda x: x.replace('backtest_result_', '').replace('.json', '')
            )
            
            # è®€å–çµæœ
            with open(selected_file, 'r') as f:
                result = json.load(f)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰äº¤æ˜“è¨˜éŒ„
            if 'trades' not in result or not result['trades']:
                st.warning("âš ï¸ æ­¤å›æ¸¬çµæœæ²’æœ‰äº¤æ˜“è¨˜éŒ„")
            else:
                trades = result['trades']
                
                # è½‰æ›ç‚º DataFrame
                trades_df = pd.DataFrame(trades)
                
                # é¡¯ç¤ºçµ±è¨ˆ
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("ç¸½äº¤æ˜“æ•¸", len(trades_df))
                
                with col2:
                    winning_trades = len(trades_df[trades_df['pnl'] > 0])
                    st.metric("ç²åˆ©äº¤æ˜“", winning_trades)
                
                with col3:
                    losing_trades = len(trades_df[trades_df['pnl'] < 0])
                    st.metric("è™§æäº¤æ˜“", losing_trades)
                
                with col4:
                    total_pnl = trades_df['pnl'].sum()
                    st.metric("ç¸½æç›Š", f"{total_pnl:.2f} USDT")
                
                # ç¯©é¸é¸é …
                st.subheader("ğŸ” ç¯©é¸äº¤æ˜“")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    trade_type = st.selectbox(
                        "äº¤æ˜“é¡å‹",
                        ["å…¨éƒ¨", "ç²åˆ©", "è™§æ"]
                    )
                
                with col2:
                    direction = st.selectbox(
                        "æ–¹å‘",
                        ["å…¨éƒ¨", "åšå¤š", "åšç©º"]
                    )
                
                with col3:
                    sort_by = st.selectbox(
                        "æ’åº",
                        ["æ™‚é–“ï¼ˆæ–°åˆ°èˆŠï¼‰", "æ™‚é–“ï¼ˆèˆŠåˆ°æ–°ï¼‰", "æç›Šï¼ˆé«˜åˆ°ä½ï¼‰", "æç›Šï¼ˆä½åˆ°é«˜ï¼‰"]
                    )
                
                # æ‡‰ç”¨ç¯©é¸
                filtered_df = trades_df.copy()
                
                if trade_type == "ç²åˆ©":
                    filtered_df = filtered_df[filtered_df['pnl'] > 0]
                elif trade_type == "è™§æ":
                    filtered_df = filtered_df[filtered_df['pnl'] < 0]
                
                if direction == "åšå¤š":
                    filtered_df = filtered_df[filtered_df['side'] == 'long']
                elif direction == "åšç©º":
                    filtered_df = filtered_df[filtered_df['side'] == 'short']
                
                # æ‡‰ç”¨æ’åº
                if sort_by == "æ™‚é–“ï¼ˆæ–°åˆ°èˆŠï¼‰":
                    filtered_df = filtered_df.sort_values('entry_time', ascending=False)
                elif sort_by == "æ™‚é–“ï¼ˆèˆŠåˆ°æ–°ï¼‰":
                    filtered_df = filtered_df.sort_values('entry_time', ascending=True)
                elif sort_by == "æç›Šï¼ˆé«˜åˆ°ä½ï¼‰":
                    filtered_df = filtered_df.sort_values('pnl', ascending=False)
                elif sort_by == "æç›Šï¼ˆä½åˆ°é«˜ï¼‰":
                    filtered_df = filtered_df.sort_values('pnl', ascending=True)
                
                # é¡¯ç¤ºäº¤æ˜“æ˜ç´°
                st.subheader(f"ğŸ“Š äº¤æ˜“æ˜ç´°ï¼ˆå…± {len(filtered_df)} ç­†ï¼‰")
                
                # æ ¼å¼åŒ–é¡¯ç¤º
                display_df = filtered_df.copy()
                
                # é¸æ“‡è¦é¡¯ç¤ºçš„åˆ—
                columns_to_show = ['entry_time', 'exit_time', 'side', 'entry_price', 'exit_price', 'quantity', 'pnl', 'pnl_pct']
                
                if all(col in display_df.columns for col in columns_to_show):
                    display_df = display_df[columns_to_show]
                    
                    # é‡å‘½ååˆ—
                    display_df.columns = ['é€²å ´æ™‚é–“', 'å‡ºå ´æ™‚é–“', 'æ–¹å‘', 'é€²å ´åƒ¹', 'å‡ºå ´åƒ¹', 'æ•¸é‡', 'æç›Š(USDT)', 'æç›Š(%)']
                    
                    # æ ¼å¼åŒ–æ•¸å€¼
                    display_df['é€²å ´åƒ¹'] = display_df['é€²å ´åƒ¹'].apply(lambda x: f"{x:.2f}")
                    display_df['å‡ºå ´åƒ¹'] = display_df['å‡ºå ´åƒ¹'].apply(lambda x: f"{x:.2f}")
                    display_df['æ•¸é‡'] = display_df['æ•¸é‡'].apply(lambda x: f"{x:.4f}")
                    display_df['æç›Š(USDT)'] = display_df['æç›Š(USDT)'].apply(lambda x: f"{x:.2f}")
                    display_df['æç›Š(%)'] = display_df['æç›Š(%)'].apply(lambda x: f"{x:.2f}%")
                    
                    # é¡¯ç¤ºè¡¨æ ¼
                    st.dataframe(display_df, use_container_width=True, height=400)
                    
                    # ä¸‹è¼‰æŒ‰éˆ•
                    csv = filtered_df.to_csv(index=False)
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰ CSV",
                        data=csv,
                        file_name=f"trades_{selected_file.replace('.json', '.csv')}",
                        mime="text/csv"
                    )
                else:
                    st.dataframe(filtered_df, use_container_width=True, height=400)
    
    elif sub_function == "å–®ç­–ç•¥å›æ¸¬çµæœ":
        st.subheader("ğŸ“ˆ å–®ç­–ç•¥å›æ¸¬çµæœ")
        
        # æŸ¥æ‰¾æ‰€æœ‰å›æ¸¬çµæœ
        result_files = glob.glob('backtest_result_*.json')
        
        if not result_files:
            st.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°å›æ¸¬çµæœæ–‡ä»¶")
            st.info("è«‹å…ˆé‹è¡Œå›æ¸¬ï¼š`python3 backtest_multi_timeframe.py`")
        else:
            # é¸æ“‡å›æ¸¬çµæœ
            selected_file = st.selectbox(
                "é¸æ“‡å›æ¸¬çµæœ",
                result_files,
                format_func=lambda x: x.replace('backtest_result_', '').replace('.json', '')
            )
            
            # è®€å–çµæœ
            with open(selected_file, 'r') as f:
                result = json.load(f)
            
            # é¡¯ç¤ºåŸºæœ¬ä¿¡æ¯
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                total_return = result.get('total_pnl_pct', 0)
                st.metric(
                    "ç¸½æ”¶ç›Š",
                    f"+{total_return:.2f}%",
                    delta=f"{result.get('total_pnl', 0):.2f} USDT"
                )
            
            with col2:
                st.metric(
                    "å‹ç‡",
                    f"{result['win_rate']:.2f}%",
                    delta=f"{result['winning_trades']}/{result['total_trades']}"
                )
            
            with col3:
                max_dd = result.get('max_drawdown_pct', result.get('max_drawdown', 0))
                st.metric(
                    "æœ€å¤§å›æ’¤",
                    f"-{max_dd:.2f}%",
                    delta=f"-{result.get('max_drawdown', 0):.2f} USDT",
                    delta_color="inverse"
                )
            
            with col4:
                st.metric(
                    "ç²åˆ©å› å­",
                    f"{result['profit_factor']:.2f}",
                    delta="å„ªç§€" if result['profit_factor'] > 1.5 else "ä¸€èˆ¬"
                )
            
            # è©³ç´°æŒ‡æ¨™
            st.subheader("ğŸ“ˆ è©³ç´°æŒ‡æ¨™")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**è³‡é‡‘æƒ…æ³**")
                st.write(f"- åˆå§‹è³‡é‡‘ï¼š{result['initial_capital']:.2f} USDT")
                st.write(f"- æœ€çµ‚è³‡é‡‘ï¼š{result['final_capital']:.2f} USDT")
                st.write(f"- æ·¨æç›Šï¼š{result.get('total_pnl', 0):.2f} USDT")
                
                st.write("**äº¤æ˜“çµ±è¨ˆ**")
                st.write(f"- ç¸½äº¤æ˜“æ•¸ï¼š{result['total_trades']}")
                st.write(f"- ç²åˆ©äº¤æ˜“ï¼š{result['winning_trades']}")
                st.write(f"- è™§æäº¤æ˜“ï¼š{result['losing_trades']}")
            
            with col2:
                st.write("**æç›Šåˆ†æ**")
                st.write(f"- å¹³å‡ç²åˆ©ï¼š{result.get('avg_win', 0):.2f} USDT")
                st.write(f"- å¹³å‡è™§æï¼š{result.get('avg_loss', 0):.2f} USDT")
                st.write(f"- ç²åˆ©å› å­ï¼š{result['profit_factor']:.2f}")
                
                st.write("**é¢¨éšªæŒ‡æ¨™**")
                st.write(f"- æœ€å¤§å›æ’¤ï¼š{max_dd:.2f}%")
                st.write(f"- å¤æ™®æ¯”ç‡ï¼š{result['sharpe_ratio']:.2f}")
            
            # æ¬Šç›Šæ›²ç·š
            if 'equity_curve' in result and result['equity_curve']:
                st.subheader("ğŸ“‰ æ¬Šç›Šæ›²ç·š")
                
                try:
                    equity_curve = result['equity_curve']
                    
                    if isinstance(equity_curve, list):
                        if len(equity_curve) > 0 and isinstance(equity_curve[0], dict):
                            equity_df = pd.DataFrame(equity_curve)
                            equity_values = equity_df['equity'].values if 'equity' in equity_df.columns else equity_df.iloc[:, 0].values
                        else:
                            equity_values = equity_curve
                    elif isinstance(equity_curve, dict):
                        equity_values = list(equity_curve.values())
                    else:
                        equity_values = [equity_curve]
                    
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(
                        x=list(range(len(equity_values))),
                        y=equity_values,
                        mode='lines',
                        name='æ¬Šç›Š',
                        line=dict(color='#00D9FF', width=2)
                    ))
                    
                    fig.update_layout(
                        title="æ¬Šç›Šè®ŠåŒ–",
                        xaxis_title="äº¤æ˜“æ¬¡æ•¸",
                        yaxis_title="æ¬Šç›Š (USDT)",
                        hovermode='x unified',
                        height=400
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.warning(f"âš ï¸ ç„¡æ³•é¡¯ç¤ºæ¬Šç›Šæ›²ç·šï¼š{str(e)}")
    
    elif sub_function == "æ§“æ¡¿å°æ¯”æ¸¬è©¦":
        st.subheader("ğŸ“ˆ æ§“æ¡¿å°æ¯”åˆ†æ")
        
        leverage_files = glob.glob('leverage_comparison_*.csv')
        
        if not leverage_files:
            st.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°æ§“æ¡¿å°æ¯”çµæœ")
            st.info("è«‹å…ˆé‹è¡Œï¼š`python3 backtest_leverage_comparison.py`")
        else:
            selected_file = st.selectbox(
                "é¸æ“‡å°æ¯”çµæœ",
                leverage_files,
                format_func=lambda x: x.replace('leverage_comparison_', '').replace('.csv', '')
            )
            
            df = pd.read_csv(selected_file)
            df['risk_adjusted'] = df['total_return'] / df['max_drawdown']
            
            st.subheader("ğŸ“Š å°æ¯”è¡¨æ ¼")
            
            display_df = df[['leverage', 'total_return', 'max_drawdown', 'win_rate', 'risk_adjusted']].copy()
            display_df.columns = ['æ§“æ¡¿', 'æ”¶ç›Šç‡(%)', 'æœ€å¤§å›æ’¤(%)', 'å‹ç‡(%)', 'é¢¨éšªèª¿æ•´æ”¶ç›Š']
            display_df['æ”¶ç›Šç‡(%)'] = display_df['æ”¶ç›Šç‡(%)'].round(2)
            display_df['æœ€å¤§å›æ’¤(%)'] = display_df['æœ€å¤§å›æ’¤(%)'].round(2)
            display_df['å‹ç‡(%)'] = display_df['å‹ç‡(%)'].round(2)
            display_df['é¢¨éšªèª¿æ•´æ”¶ç›Š'] = display_df['é¢¨éšªèª¿æ•´æ”¶ç›Š'].round(2)
            
            st.dataframe(display_df, use_container_width=True)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ğŸ“ˆ æ”¶ç›Šç‡ vs æ§“æ¡¿")
                fig1 = px.bar(df, x='leverage', y='total_return', 
                             title='ä¸åŒæ§“æ¡¿çš„æ”¶ç›Šç‡',
                             labels={'leverage': 'æ§“æ¡¿', 'total_return': 'æ”¶ç›Šç‡(%)'},
                             color='total_return',
                             color_continuous_scale='RdYlGn')
                st.plotly_chart(fig1, use_container_width=True)
            
            with col2:
                st.subheader("ğŸ“‰ å›æ’¤ vs æ§“æ¡¿")
                fig2 = px.bar(df, x='leverage', y='max_drawdown',
                             title='ä¸åŒæ§“æ¡¿çš„æœ€å¤§å›æ’¤',
                             labels={'leverage': 'æ§“æ¡¿', 'max_drawdown': 'æœ€å¤§å›æ’¤(%)'},
                             color='max_drawdown',
                             color_continuous_scale='RdYlGn_r')
                st.plotly_chart(fig2, use_container_width=True)
            
            best_idx = df['risk_adjusted'].idxmax()
            best_leverage = int(df.loc[best_idx, 'leverage'])
            best_return = df.loc[best_idx, 'total_return']
            best_drawdown = df.loc[best_idx, 'max_drawdown']
            
            st.success(f"""
            ğŸ’¡ **æ¨è–¦é…ç½®**ï¼š{best_leverage}x æ§“æ¡¿
            - æ”¶ç›Šç‡ï¼š+{best_return:.2f}%
            - æœ€å¤§å›æ’¤ï¼š-{best_drawdown:.2f}%
            - é¢¨éšªèª¿æ•´æ”¶ç›Šï¼š{df.loc[best_idx, 'risk_adjusted']:.2f}
            """)

# ==================== 2. å¯¦ç›¤äº¤æ˜“ ====================
elif category == "2ï¸âƒ£ å¯¦ç›¤äº¤æ˜“":
    st.header("ğŸ”´ å¯¦ç›¤äº¤æ˜“")
    
    sub_function = st.sidebar.selectbox(
        "é¸æ“‡åŠŸèƒ½",
        [
            "å¯¦ç›¤ç‹€æ…‹ç›£æ§",
            "ç•¶å‰æŒå€‰",
            "å¯¦ç›¤äº¤æ˜“è¨˜éŒ„",
            "Telegram é€šçŸ¥è¨­ç½®"
        ]
    )
    
    if sub_function == "å¯¦ç›¤ç‹€æ…‹ç›£æ§":
        st.subheader("ğŸ“¡ å¯¦ç›¤ç‹€æ…‹ç›£æ§")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å¯¦ç›¤æ—¥èªŒ
        log_file = Path("logs/trading.log")
        
        if not log_file.exists():
            st.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°å¯¦ç›¤æ—¥èªŒæ–‡ä»¶")
            st.info("ğŸ’¡ å¯¦ç›¤äº¤æ˜“åŠŸèƒ½éœ€è¦é€šéå‘½ä»¤è¡Œå•Ÿå‹•ï¼š")
            st.code("python3 cli.py live --strategy multi-timeframe-aggressive")
        else:
            # è®€å–æœ€æ–°çš„æ—¥èªŒ
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    recent_logs = lines[-100:]  # æœ€è¿‘ 100 è¡Œ
                
                # è§£ææ—¥èªŒçµ±è¨ˆ
                total_lines = len(recent_logs)
                error_count = sum(1 for line in recent_logs if 'ERROR' in line)
                warning_count = sum(1 for line in recent_logs if 'WARNING' in line)
                trade_signals = sum(1 for line in recent_logs if 'äº¤æ˜“ä¿¡è™Ÿ' in line or 'SIGNAL' in line)
                
                # é¡¯ç¤ºçµ±è¨ˆ
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("æ—¥èªŒè¡Œæ•¸", total_lines)
                
                with col2:
                    st.metric("äº¤æ˜“ä¿¡è™Ÿ", trade_signals)
                
                with col3:
                    st.metric("è­¦å‘Š", warning_count, delta_color="inverse")
                
                with col4:
                    st.metric("éŒ¯èª¤", error_count, delta_color="inverse")
                
                # é¡¯ç¤ºæœ€æ–°æ—¥èªŒ
                st.subheader("ğŸ“ æœ€æ–°æ—¥èªŒï¼ˆæœ€è¿‘ 50 è¡Œï¼‰")
                
                log_text = ''.join(recent_logs[-50:])
                st.text_area("æ—¥èªŒå…§å®¹", log_text, height=400)
                
                # è‡ªå‹•åˆ·æ–°é¸é …
                auto_refresh = st.checkbox("è‡ªå‹•åˆ·æ–°ï¼ˆæ¯ 5 ç§’ï¼‰")
                
                if auto_refresh:
                    import time
                    time.sleep(5)
                    st.rerun()
            
            except Exception as e:
                st.error(f"âŒ è®€å–æ—¥èªŒå¤±æ•—ï¼š{str(e)}")
        
        st.divider()
        
        st.write("**åŠŸèƒ½èªªæ˜**ï¼š")
        st.write("- å–®ç­–ç•¥å¯¦ç›¤é‹è¡Œ")
        st.write("- å¤šç­–ç•¥ä¸¦è¡Œé‹è¡Œ")
        st.write("- ä¹¾è·‘æ¨¡å¼ï¼ˆä¸å¯¦éš›ä¸‹å–®ï¼‰")
        st.write("- è‡ªå‹•ä¸‹å–®")
        st.write("- Telegram å¯¦æ™‚é€šçŸ¥")
        st.write("- è‡ªå‹•é¢¨éšªæ§åˆ¶")
    
    elif sub_function == "ç•¶å‰æŒå€‰":
        st.subheader("ğŸ’¼ ç•¶å‰æŒå€‰")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æŒå€‰è¨˜éŒ„æ–‡ä»¶
        position_file = Path("data/trade_history/current_positions.json")
        
        if not position_file.exists():
            st.info("âš ï¸ æ²’æœ‰ç•¶å‰æŒå€‰è¨˜éŒ„")
            st.write("å¯¦ç›¤é‹è¡Œæ™‚æœƒè‡ªå‹•è¨˜éŒ„æŒå€‰ä¿¡æ¯")
        else:
            try:
                with open(position_file, 'r') as f:
                    positions = json.load(f)
                
                if not positions:
                    st.info("âœ… ç•¶å‰ç„¡æŒå€‰")
                else:
                    st.write(f"**æŒå€‰æ•¸é‡**ï¼š{len(positions)}")
                    
                    # é¡¯ç¤ºæ¯å€‹æŒå€‰
                    for i, pos in enumerate(positions):
                        with st.expander(f"æŒå€‰ {i+1}: {pos.get('symbol', 'N/A')} - {pos.get('side', 'N/A')}"):
                            col1, col2, col3 = st.columns(3)
                            
                            with col1:
                                st.write(f"**äº¤æ˜“å°**ï¼š{pos.get('symbol', 'N/A')}")
                                st.write(f"**æ–¹å‘**ï¼š{pos.get('side', 'N/A')}")
                                st.write(f"**æ•¸é‡**ï¼š{pos.get('quantity', 0):.4f}")
                            
                            with col2:
                                st.write(f"**é€²å ´åƒ¹**ï¼š{pos.get('entry_price', 0):.2f}")
                                st.write(f"**ç•¶å‰åƒ¹**ï¼š{pos.get('current_price', 0):.2f}")
                                st.write(f"**æ§“æ¡¿**ï¼š{pos.get('leverage', 1)}x")
                            
                            with col3:
                                pnl = pos.get('unrealized_pnl', 0)
                                pnl_pct = pos.get('unrealized_pnl_pct', 0)
                                st.metric("æœªå¯¦ç¾æç›Š", f"{pnl:.2f} USDT", f"{pnl_pct:.2f}%")
                                st.write(f"**æ­¢æåƒ¹**ï¼š{pos.get('stop_loss', 0):.2f}")
                                st.write(f"**ç›®æ¨™åƒ¹**ï¼š{pos.get('take_profit', 0):.2f}")
            
            except Exception as e:
                st.error(f"âŒ è®€å–æŒå€‰å¤±æ•—ï¼š{str(e)}")
    
    elif sub_function == "å¯¦ç›¤äº¤æ˜“è¨˜éŒ„":
        st.subheader("ğŸ“Š å¯¦ç›¤äº¤æ˜“è¨˜éŒ„")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰äº¤æ˜“è¨˜éŒ„
        trade_history_files = glob.glob('data/trade_history/trades_*.json')
        
        if not trade_history_files:
            st.info("âš ï¸ æ²’æœ‰å¯¦ç›¤äº¤æ˜“è¨˜éŒ„")
        else:
            # é¸æ“‡æ—¥æœŸ
            selected_file = st.selectbox(
                "é¸æ“‡æ—¥æœŸ",
                trade_history_files,
                format_func=lambda x: x.replace('data/trade_history/trades_', '').replace('.json', '')
            )
            
            # è®€å–äº¤æ˜“è¨˜éŒ„
            with open(selected_file, 'r') as f:
                trades = json.load(f)
            
            if not trades:
                st.info("è©²æ—¥æœŸæ²’æœ‰äº¤æ˜“è¨˜éŒ„")
            else:
                # è½‰æ›ç‚º DataFrame
                trades_df = pd.DataFrame(trades)
                
                # é¡¯ç¤ºçµ±è¨ˆ
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("ç¸½äº¤æ˜“æ•¸", len(trades_df))
                
                with col2:
                    winning = len(trades_df[trades_df['pnl'] > 0])
                    st.metric("ç²åˆ©äº¤æ˜“", winning)
                
                with col3:
                    losing = len(trades_df[trades_df['pnl'] < 0])
                    st.metric("è™§æäº¤æ˜“", losing)
                
                with col4:
                    total_pnl = trades_df['pnl'].sum()
                    st.metric("ç¸½æç›Š", f"{total_pnl:.2f} USDT")
                
                # é¡¯ç¤ºäº¤æ˜“åˆ—è¡¨
                st.dataframe(trades_df, use_container_width=True)
    
    else:  # Telegram é€šçŸ¥è¨­ç½®
        st.subheader("ğŸ“¢ Telegram é€šçŸ¥è¨­ç½®")
        
        try:
            import yaml
            with open('system_config.yaml', 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            telegram_config = config.get('notifications', {}).get('telegram', {})
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**ç•¶å‰è¨­ç½®**")
                enabled = telegram_config.get('enabled', False)
                st.write(f"- ç‹€æ…‹ï¼š{'âœ… å•Ÿç”¨' if enabled else 'âŒ ç¦ç”¨'}")
                st.write(f"- Bot Tokenï¼š{'å·²è¨­ç½®' if telegram_config.get('bot_token') else 'æœªè¨­ç½®'}")
                st.write(f"- Chat IDï¼š{'å·²è¨­ç½®' if telegram_config.get('chat_id') else 'æœªè¨­ç½®'}")
            
            with col2:
                st.write("**é€šçŸ¥é¡å‹**")
                notify_types = telegram_config.get('notify_on', [])
                st.write(f"- äº¤æ˜“ä¿¡è™Ÿï¼š{'âœ…' if 'signal' in notify_types else 'âŒ'}")
                st.write(f"- è¨‚å–®åŸ·è¡Œï¼š{'âœ…' if 'order' in notify_types else 'âŒ'}")
                st.write(f"- é¢¨éšªè­¦å ±ï¼š{'âœ…' if 'risk' in notify_types else 'âŒ'}")
                st.write(f"- éŒ¯èª¤ï¼š{'âœ…' if 'error' in notify_types else 'âŒ'}")
            
            st.divider()
            
            st.write("**æ¸¬è©¦ Telegram é€£æ¥**")
            if st.button("ç™¼é€æ¸¬è©¦æ¶ˆæ¯"):
                st.info("è«‹åœ¨å‘½ä»¤è¡Œé‹è¡Œï¼š`python3 test_telegram.py`")
        
        except Exception as e:
            st.error(f"âŒ è®€å–é…ç½®å¤±æ•—ï¼š{str(e)}")

# ==================== 3. åƒæ•¸å„ªåŒ– ====================
elif category == "3ï¸âƒ£ åƒæ•¸å„ªåŒ–":
    st.header("ğŸ”§ åƒæ•¸å„ªåŒ–")
    
    sub_function = st.sidebar.selectbox(
        "é¸æ“‡åŠŸèƒ½",
        [
            "å„ªåŒ–çµæœæŸ¥çœ‹",
            "åƒæ•¸æ•æ„Ÿåº¦åˆ†æ",
            "å„ªåŒ–ä»»å‹™ç®¡ç†"
        ]
    )
    
    if sub_function == "å„ªåŒ–çµæœæŸ¥çœ‹":
        st.subheader("ğŸ“Š å„ªåŒ–çµæœæŸ¥çœ‹")
        
        # æŸ¥æ‰¾å„ªåŒ–çµæœæ–‡ä»¶
        optimize_files = glob.glob('data/backtest_results/optimize_*.json')
        
        if not optimize_files:
            st.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°å„ªåŒ–çµæœæ–‡ä»¶")
            st.info("è«‹å…ˆé‹è¡Œå„ªåŒ–ï¼š`python3 cli.py optimize --strategy multi-timeframe-aggressive --method grid`")
        else:
            # é¸æ“‡å„ªåŒ–çµæœ
            selected_file = st.selectbox(
                "é¸æ“‡å„ªåŒ–çµæœ",
                optimize_files,
                format_func=lambda x: x.replace('data/backtest_results/optimize_', '').replace('.json', '')
            )
            
            # è®€å–çµæœ
            with open(selected_file, 'r') as f:
                result = json.load(f)
            
            # é¡¯ç¤ºåŸºæœ¬ä¿¡æ¯
            st.subheader("ğŸ“‹ å„ªåŒ–ä¿¡æ¯")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.write(f"**å„ªåŒ–æ–¹æ³•**ï¼š{result.get('method', 'N/A')}")
                st.write(f"**æ¸¬è©¦çµ„åˆæ•¸**ï¼š{result.get('total_combinations_tested', 0)}")
            
            with col2:
                st.write(f"**å„ªåŒ–æ™‚é–“**ï¼š{result.get('optimization_time', 0):.2f} ç§’")
                st.write(f"**æœ€ä½³è©•åˆ†**ï¼š{result.get('best_score', 0):.4f}")
            
            with col3:
                train_perf = result.get('train_performance', {})
                val_perf = result.get('validation_performance', {})
                st.write(f"**è¨“ç·´é›†å‹ç‡**ï¼š{train_perf.get('win_rate', 0):.2%}")
                st.write(f"**é©—è­‰é›†å‹ç‡**ï¼š{val_perf.get('win_rate', 0):.2%}")
            
            # æœ€ä½³åƒæ•¸
            st.subheader("ğŸ¯ æœ€ä½³åƒæ•¸")
            
            best_params = result.get('best_params', {})
            
            if best_params:
                # åˆ†çµ„é¡¯ç¤ºåƒæ•¸
                param_groups = {}
                for key, value in best_params.items():
                    if '.' in key:
                        group = key.split('.')[0]
                        param_name = '.'.join(key.split('.')[1:])
                    else:
                        group = 'å…¶ä»–'
                        param_name = key
                    
                    if group not in param_groups:
                        param_groups[group] = {}
                    param_groups[group][param_name] = value
                
                # é¡¯ç¤ºåˆ†çµ„åƒæ•¸
                cols = st.columns(len(param_groups))
                
                for i, (group, params) in enumerate(param_groups.items()):
                    with cols[i]:
                        st.write(f"**{group}**")
                        for param, value in params.items():
                            if isinstance(value, float):
                                st.write(f"- {param}: {value:.4f}")
                            else:
                                st.write(f"- {param}: {value}")
            
            # æ€§èƒ½å°æ¯”
            st.subheader("ğŸ“ˆ æ€§èƒ½å°æ¯”")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**è¨“ç·´é›†**")
                st.write(f"- ç¸½äº¤æ˜“æ•¸ï¼š{train_perf.get('total_trades', 0)}")
                st.write(f"- å‹ç‡ï¼š{train_perf.get('win_rate', 0):.2%}")
                st.write(f"- ç¸½æç›Šï¼š{train_perf.get('total_pnl', 0):.2f} USDT")
                st.write(f"- ç²åˆ©å› å­ï¼š{train_perf.get('profit_factor', 0):.2f}")
                st.write(f"- å¤æ™®æ¯”ç‡ï¼š{train_perf.get('sharpe_ratio', 0):.2f}")
            
            with col2:
                st.write("**é©—è­‰é›†**")
                st.write(f"- ç¸½äº¤æ˜“æ•¸ï¼š{val_perf.get('total_trades', 0)}")
                st.write(f"- å‹ç‡ï¼š{val_perf.get('win_rate', 0):.2%}")
                st.write(f"- ç¸½æç›Šï¼š{val_perf.get('total_pnl', 0):.2f} USDT")
                st.write(f"- ç²åˆ©å› å­ï¼š{val_perf.get('profit_factor', 0):.2f}")
                st.write(f"- å¤æ™®æ¯”ç‡ï¼š{val_perf.get('sharpe_ratio', 0):.2f}")
            
            # åƒæ•¸æ•æ„Ÿåº¦
            if 'parameter_sensitivity' in result:
                st.subheader("ğŸ“Š åƒæ•¸æ•æ„Ÿåº¦")
                
                sensitivity = result['parameter_sensitivity']
                
                for param_name, scores in sensitivity.items():
                    if scores:
                        st.write(f"**{param_name}**")
                        
                        # è½‰æ›ç‚º DataFrame
                        df = pd.DataFrame(scores, columns=['å€¼', 'è©•åˆ†'])
                        
                        # ç¹ªè£½åœ–è¡¨
                        fig = px.scatter(df, x='å€¼', y='è©•åˆ†', 
                                       title=f'{param_name} æ•æ„Ÿåº¦åˆ†æ',
                                       trendline="lowess")
                        st.plotly_chart(fig, use_container_width=True)
    
    elif sub_function == "å„ªåŒ–ä»»å‹™ç®¡ç†":
        st.subheader("ğŸ¯ åƒæ•¸å„ªåŒ–")
        st.info("ğŸ’¡ åƒæ•¸å„ªåŒ–éœ€è¦é€šéå‘½ä»¤è¡Œå•Ÿå‹•ï¼š")
        st.code("python3 cli.py optimize --strategy multi-timeframe-aggressive --method grid")
        
        st.write("**æ”¯æŒçš„å„ªåŒ–æ–¹æ³•**ï¼š")
        st.write("- ç¶²æ ¼æœç´¢ï¼ˆGrid Searchï¼‰")
        st.write("- éš¨æ©Ÿæœç´¢ï¼ˆRandom Searchï¼‰")
        st.write("- è²è‘‰æ–¯å„ªåŒ–ï¼ˆBayesian Optimizationï¼‰")

# ==================== 4. è™§æåˆ†æ ====================
elif category == "4ï¸âƒ£ è™§æåˆ†æ":
    st.header("ğŸ“‰ è™§æåˆ†æ")
    
    sub_function = st.sidebar.selectbox(
        "é¸æ“‡åŠŸèƒ½",
        [
            "è™§æåŸå› åˆ†é¡",
            "è™§ææ¨¡å¼è­˜åˆ¥",
            "æ”¹é€²å»ºè­°"
        ]
    )
    
    st.subheader("ğŸ” è™§æåˆ†æå·¥å…·")
    st.info("ğŸ’¡ è™§æåˆ†æéœ€è¦é€šé Python è…³æœ¬é‹è¡Œï¼š")
    st.code("python3 example_loss_analyzer.py")

# ==================== 5. æ€§èƒ½ç›£æ§ ====================
elif category == "5ï¸âƒ£ æ€§èƒ½ç›£æ§":
    st.header("ğŸ“Š æ€§èƒ½ç›£æ§")
    
    sub_function = st.sidebar.selectbox(
        "é¸æ“‡åŠŸèƒ½",
        [
            "å¯¦æ™‚æŒ‡æ¨™è¿½è¹¤",
            "ç•°å¸¸æª¢æ¸¬",
            "ç­–ç•¥é€€åŒ–æª¢æ¸¬"
        ]
    )
    
    st.subheader("ğŸ“ˆ æ€§èƒ½ç›£æ§")
    st.info("ğŸ’¡ æ€§èƒ½ç›£æ§éœ€è¦é€šé Python è…³æœ¬é‹è¡Œï¼š")
    st.code("python3 example_performance_monitor.py")

# ==================== 6. äº¤æ˜“è¦†ç›¤ ====================
elif category == "6ï¸âƒ£ äº¤æ˜“è¦†ç›¤":
    st.header("ğŸ“ äº¤æ˜“è¦†ç›¤")
    
    sub_function = st.sidebar.selectbox(
        "é¸æ“‡åŠŸèƒ½",
        [
            "BingX äº¤æ˜“åˆ†æ",
            "äº¤æ˜“è¨˜éŒ„ç®¡ç†",
            "åŸ·è¡Œè³ªé‡è©•åˆ†",
            "è¦†ç›¤å ±å‘Š"
        ]
    )
    
    if sub_function == "BingX äº¤æ˜“åˆ†æ":
        st.subheader("ğŸ’° BingX äº¤æ˜“åˆ†æ")
        
        try:
            from å®Œæ•´äº¤æ˜“åˆ†æ import BingXTradeAnalyzer
            
            analyzer = BingXTradeAnalyzer()
            analyzer.load_data()
            
            order_analysis = analyzer.analyze_orders()
            trans_analysis = analyzer.analyze_transactions()
            
            if order_analysis is None and trans_analysis is None:
                st.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°äº¤æ˜“è¨˜éŒ„")
                st.info("è«‹ç¢ºä¿ bingxHistory ç›®éŒ„ä¸­æœ‰ Order_History å’Œ Transaction_History æ–‡ä»¶")
            else:
                st.success(f"âœ… æˆåŠŸè¼‰å…¥äº¤æ˜“æ•¸æ“š")
                
                # è¨‚å–®åˆ†æ
                if order_analysis:
                    st.subheader("ğŸ“‹ è¨‚å–®åˆ†æ")
                    
                    summary = order_analysis['summary']
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("ç¸½è¨‚å–®æ•¸", summary['total_orders'])
                    
                    with col2:
                        st.metric("å‹ç‡", f"{summary['win_rate']:.2f}%",
                                 delta="å„ªç§€" if summary['win_rate'] >= 50 else "éœ€æ”¹é€²",
                                 delta_color="normal" if summary['win_rate'] >= 50 else "inverse")
                    
                    with col3:
                        st.metric("ç¸½ç›ˆè™§", f"{summary['total_pnl']:.2f} USDT",
                                 delta_color="normal" if summary['total_pnl'] >= 0 else "inverse")
                    
                    with col4:
                        st.metric("ç¸½æ‰‹çºŒè²»", f"{summary['total_fees']:.2f} USDT",
                                 delta_color="inverse")
                    
                    # æŒ‰å¸³æˆ¶é¡å‹åˆ†æ
                    st.subheader("ğŸ’¼ æŒ‰å¸³æˆ¶é¡å‹åˆ†æ")
                    by_account = order_analysis['by_account']
                    st.dataframe(by_account, use_container_width=True)
        
        except Exception as e:
            st.error(f"âŒ åˆ†æå¤±æ•—ï¼š{str(e)}")
    
    elif sub_function == "äº¤æ˜“è¨˜éŒ„ç®¡ç†":
        st.subheader("ğŸ“ äº¤æ˜“è¨˜éŒ„ç®¡ç†")
        
        st.info("""
        **åŠŸèƒ½èªªæ˜**ï¼š
        - ä¸Šå‚³ BingX Order_History æ–‡ä»¶ï¼ˆExcel æˆ– CSVï¼‰
        - è‡ªå‹•æŒ‰ Order No å»é‡
        - æŒ‰å¤©ä¿å­˜åˆ° `data/review_history/bingx/orders/`
        - æ”¯æŒå¢é‡æ›´æ–°
        """)
        
        # æ­¥é©Ÿ 1ï¼šé¸æ“‡äº¤æ˜“æ‰€
        st.subheader("1ï¸âƒ£ é¸æ“‡äº¤æ˜“æ‰€")
        exchange = st.radio(
            "äº¤æ˜“æ‰€",
            ["BingX", "Binanceï¼ˆæœªä¾†ï¼‰", "OKXï¼ˆæœªä¾†ï¼‰"],
            disabled=[False, True, True]
        )
        
        if exchange != "BingX":
            st.warning("âš ï¸ ç›®å‰åªæ”¯æŒ BingX")
        else:
            # æ­¥é©Ÿ 2ï¼šä¸Šå‚³æ–‡ä»¶
            st.subheader("2ï¸âƒ£ ä¸Šå‚³ Order_History")
            
            uploaded_file = st.file_uploader(
                "é¸æ“‡ Order_History æ–‡ä»¶",
                type=['xlsx', 'xls', 'csv'],
                help="å¾ BingX åŒ¯å‡ºçš„ Order_History æ–‡ä»¶"
            )
        
        if uploaded_file is not None:
            try:
                # æª¢æ¸¬æ–‡ä»¶çœŸå¯¦é¡å‹
                uploaded_file.seek(0)
                file_header = uploaded_file.read(4)
                uploaded_file.seek(0)
                
                is_excel = file_header[:2] == b'PK'
                file_extension = uploaded_file.name.split('.')[-1].lower()
                
                if is_excel:
                    st.caption(f"ğŸ“Œ æª¢æ¸¬åˆ° Excel æ ¼å¼ï¼ˆå‰¯æª”åï¼š.{file_extension}ï¼‰")
                    file_extension = 'xlsx'
                
                # è®€å–æ–‡ä»¶
                all_orders = []
                
                if file_extension == 'csv':
                    # CSV æ ¼å¼
                    encodings = ['utf-8', 'utf-8-sig', 'big5', 'gb2312', 'gbk', 'gb18030', 'latin1', 'cp1252']
                    df = None
                    
                    for encoding in encodings:
                        try:
                            uploaded_file.seek(0)
                            df = pd.read_csv(uploaded_file, encoding=encoding)
                            st.caption(f"ä½¿ç”¨ç·¨ç¢¼ï¼š{encoding}")
                            break
                        except:
                            continue
                    
                    if df is None:
                        st.error("âŒ ç„¡æ³•è®€å– CSV æ–‡ä»¶")
                    else:
                        # æ¨æ–·å¸³æˆ¶é¡å‹
                        if 'Standard' in uploaded_file.name:
                            df['account_type'] = 'Standard_Futures'
                        elif 'Perpetual' in uploaded_file.name or 'USDâ“ˆ' in uploaded_file.name:
                            df['account_type'] = 'USDâ“¢_M_Perpetual_Futures'
                        else:
                            df['account_type'] = 'Unknown'
                        
                        all_orders.append(df)
                
                else:
                    # Excel æ ¼å¼ï¼ˆå¤šå€‹å·¥ä½œè¡¨ï¼‰
                    xl = pd.ExcelFile(uploaded_file)
                    
                    for sheet_name in xl.sheet_names:
                        df = pd.read_excel(uploaded_file, sheet_name=sheet_name)
                        if len(df) > 0:
                            df['account_type'] = sheet_name
                            all_orders.append(df)
                
                if not all_orders:
                    st.warning("âš ï¸ æ–‡ä»¶ä¸­æ²’æœ‰æ•¸æ“š")
                else:
                    # åˆä½µæ‰€æœ‰è¨‚å–®
                    combined_df = pd.concat(all_orders, ignore_index=True)
                
                # æ­¥é©Ÿ 3ï¼šé è¦½æ•¸æ“š
                st.subheader("3ï¸âƒ£ é è¦½æ•¸æ“š")
                
                    # è­˜åˆ¥ Order No æ¬„ä½
                    order_no_col = None
                    for col in ['Order No', 'Order No.', 'order_no', 'OrderNo']:
                        if col in combined_df.columns:
                            order_no_col = col
                            break
                    
                    if not order_no_col:
                        st.error("âŒ æ‰¾ä¸åˆ° Order No æ¬„ä½")
                        st.write("å¯ç”¨æ¬„ä½ï¼š", ", ".join(combined_df.columns.tolist()))
                    else:
                        # çµ±è¨ˆä¿¡æ¯
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("ç¸½è¨‚å–®æ•¸", len(combined_df))
                        
                        with col2:
                            # æ™‚é–“ç¯„åœ
                            time_cols = ['closeTime(UTC+8)', 'close_time', 'time']
                            time_col = None
                            for col in time_cols:
                                if col in combined_df.columns:
                                    time_col = col
                                    break
                            
                            if time_col:
                                combined_df[time_col] = pd.to_datetime(combined_df[time_col], errors='coerce')
                                min_date = combined_df[time_col].min()
                                max_date = combined_df[time_col].max()
                                st.write(f"**æ™‚é–“ç¯„åœ**")
                                st.write(f"{min_date.date()} è‡³ {max_date.date()}")
                        
                        with col3:
                            # å¸³æˆ¶é¡å‹åˆ†ä½ˆ
                            account_counts = combined_df['account_type'].value_counts()
                            st.write("**å¸³æˆ¶é¡å‹**")
                            for acc_type, count in account_counts.items():
                                st.write(f"- {acc_type}: {count}")
                        
                        # æª¢æŸ¥é‡è¤‡
                        st.subheader("4ï¸âƒ£ æª¢æŸ¥é‡è¤‡")
                        
                        # è¼‰å…¥å·²å­˜åœ¨çš„ Order No
                        order_index_file = Path("data/review_history/bingx/metadata/order_index.json")
                        existing_orders = set()
                        
                        if order_index_file.exists():
                            try:
                                with open(order_index_file, 'r', encoding='utf-8') as f:
                                    index_data = json.load(f)
                                    existing_orders = set(index_data.get('order_numbers', []))
                            except:
                                pass
                        
                        # æª¢æŸ¥ç•¶å‰æ–‡ä»¶ä¸­çš„ Order No
                        current_orders = set(combined_df[order_no_col].astype(str).tolist())
                        duplicate_orders = current_orders & existing_orders
                        new_orders = current_orders - existing_orders
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.metric("æ–°è¨‚å–®", len(new_orders), delta="å°‡è¢«ä¿å­˜")
                        
                        with col2:
                            st.metric("é‡è¤‡è¨‚å–®", len(duplicate_orders), delta="å°‡è¢«è·³é", delta_color="inverse")
                        
                        if len(duplicate_orders) > 0:
                            with st.expander(f"æŸ¥çœ‹ {len(duplicate_orders)} å€‹é‡è¤‡çš„ Order No"):
                                st.write(list(duplicate_orders)[:20])
                                if len(duplicate_orders) > 20:
                                    st.write(f"... é‚„æœ‰ {len(duplicate_orders) - 20} å€‹")
                        
                        # æ­¥é©Ÿ 5ï¼šè™•ç†é¸é …
                        st.subheader("5ï¸âƒ£ è™•ç†é¸é …")
                        
                        duplicate_action = st.radio(
                            "é‡è¤‡è¨‚å–®è™•ç†æ–¹å¼",
                            ["è·³éé‡è¤‡ï¼ˆæ¨è–¦ï¼‰", "æ›´æ–°é‡è¤‡", "ä¿ç•™æ‰€æœ‰"],
                            help="è·³éï¼šåªä¿å­˜æ–°è¨‚å–® | æ›´æ–°ï¼šç”¨æ–°æ•¸æ“šè¦†è“‹ | ä¿ç•™æ‰€æœ‰ï¼šå…è¨±é‡è¤‡"
                        )
                        
                        # æ­¥é©Ÿ 6ï¼šè½‰æ›ä¸¦ä¿å­˜
                        st.subheader("6ï¸âƒ£ è½‰æ›ä¸¦ä¿å­˜")
                        
                        if st.button("ğŸ”„ è½‰æ›ä¸¦ä¿å­˜", type="primary"):
                            try:
                                with st.spinner("æ­£åœ¨è™•ç†..."):
                                    # å‰µå»ºç›®éŒ„
                                    base_dir = Path("data/review_history/bingx")
                                    orders_dir = base_dir / "orders"
                                    metadata_dir = base_dir / "metadata"
                                    
                                    orders_dir.mkdir(parents=True, exist_ok=True)
                                    metadata_dir.mkdir(parents=True, exist_ok=True)
                                    
                                    # è™•ç†æ¯å€‹è¨‚å–®
                                    saved_count = 0
                                    skipped_count = 0
                                    updated_count = 0
                                    
                                    # æŒ‰æ—¥æœŸåˆ†çµ„
                                    if time_col:
                                        combined_df['date'] = pd.to_datetime(combined_df[time_col], errors='coerce').dt.date
                                        grouped = combined_df.groupby('date')
                                    else:
                                        # å¦‚æœæ²’æœ‰æ™‚é–“æ¬„ä½ï¼Œå…¨éƒ¨ä¿å­˜åˆ°ä¸€å€‹æ–‡ä»¶
                                        grouped = [(datetime.now().date(), combined_df)]
                                    
                                    new_order_numbers = []
                                    
                                    for date, group in grouped:
                                        if pd.isna(date):
                                            continue
                                        
                                        # æ–‡ä»¶è·¯å¾‘
                                        year = date.year
                                        month = f"{date.month:02d}"
                                        day_file = f"{date.strftime('%Y%m%d')}.json"
                                        
                                        file_path = orders_dir / str(year) / month / day_file
                                        file_path.parent.mkdir(parents=True, exist_ok=True)
                                        
                                        # è®€å–å·²å­˜åœ¨çš„æ•¸æ“š
                                        existing_data = []
                                        if file_path.exists():
                                            try:
                                                with open(file_path, 'r', encoding='utf-8') as f:
                                                    existing_data = json.load(f)
                                            except:
                                                pass
                                        
                                        # è½‰æ›ç•¶å¤©çš„è¨‚å–®
                                        day_orders = []
                                        
                                        for _, row in group.iterrows():
                                            order_no = str(row.get(order_no_col, ''))
                                            
                                            # æª¢æŸ¥é‡è¤‡
                                            if order_no in existing_orders:
                                                if "è·³é" in duplicate_action:
                                                    skipped_count += 1
                                                    continue
                                                elif "æ›´æ–°" in duplicate_action:
                                                    # å¾å·²å­˜åœ¨æ•¸æ“šä¸­ç§»é™¤èˆŠçš„
                                                    existing_data = [o for o in existing_data if o.get('order_no') != order_no]
                                                    updated_count += 1
                                            
                                            # è½‰æ›ç‚ºæ¨™æº–æ ¼å¼
                                            order = {
                                                'order_no': order_no,
                                                'trade_id': f"bingx_{order_no}",
                                                'source': 'bingx',
                                                'account_type': str(row.get('account_type', '')),
                                                'symbol': str(row.get('symbol', '')),
                                                'side': str(row.get('side', '')),
                                                'open_time': str(row.get('openTime(UTC+8)', '')),
                                                'close_time': str(row.get('closeTime(UTC+8)', '')),
                                                'entry_price': float(row.get('openPrice', 0)),
                                                'exit_price': float(row.get('closePrice', 0)),
                                                'quantity': float(row.get('quantity', 0)),
                                                'leverage': float(row.get('leverage', 1)),
                                                'pnl': float(row.get('Realized PNL', 0)),
                                                'fee': float(row.get('fees', 0)),
                                                'uploaded_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                                                'file_source': uploaded_file.name
                                            }
                                            
                                            day_orders.append(order)
                                            new_order_numbers.append(order_no)
                                            saved_count += 1
                                        
                                        # åˆä½µä¸¦ä¿å­˜
                                        if day_orders:
                                            all_day_orders = existing_data + day_orders
                                            
                                            with open(file_path, 'w', encoding='utf-8') as f:
                                                json.dump(all_day_orders, f, indent=2, ensure_ascii=False)
                                    
                                    # æ›´æ–°ç´¢å¼•
                                    all_order_numbers = list(existing_orders | set(new_order_numbers))
                                    
                                    index_data = {
                                        'order_numbers': all_order_numbers,
                                        'total_orders': len(all_order_numbers),
                                        'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                    }
                                    
                                    with open(order_index_file, 'w', encoding='utf-8') as f:
                                        json.dump(index_data, f, indent=2, ensure_ascii=False)
                                    
                                    # é¡¯ç¤ºçµæœ
                                    st.success("âœ… è½‰æ›å®Œæˆï¼")
                                    
                                    col1, col2, col3 = st.columns(3)
                                    
                                    with col1:
                                        st.metric("å·²ä¿å­˜", saved_count)
                                    
                                    with col2:
                                        st.metric("å·²è·³é", skipped_count)
                                    
                                    with col3:
                                        st.metric("å·²æ›´æ–°", updated_count)
                                    
                                    st.info(f"ğŸ“ ä¿å­˜ä½ç½®ï¼š`data/review_history/bingx/orders/`")
                                    st.info(f"ğŸ“‹ ç´¢å¼•å·²æ›´æ–°ï¼š{len(all_order_numbers)} å€‹ Order No")
                            
                            except Exception as e:
                                st.error(f"âŒ ä¿å­˜å¤±æ•—ï¼š{str(e)}")
                                import traceback
                                st.code(traceback.format_exc())
                    for col in time_cols:
                        if col in combined_df.columns:
                            time_col = col
                            break
                    
                    if time_col:
                        combined_df[time_col] = pd.to_datetime(combined_df[time_col], errors='coerce')
                        min_date = combined_df[time_col].min()
                        max_date = combined_df[time_col].max()
                        st.write(f"**æ™‚é–“ç¯„åœ**")
                        st.write(f"{min_date.date()} è‡³ {max_date.date()}")
                
                with col3:
                    # å¸³æˆ¶é¡å‹åˆ†ä½ˆ
                    account_counts = combined_df['account_type'].value_counts()
                    st.write("**å¸³æˆ¶é¡å‹**")
                    for acc_type, count in account_counts.items():
                        st.write(f"- {acc_type}: {count}")
                
                # æª¢æŸ¥é‡è¤‡
                st.subheader("4ï¸âƒ£ æª¢æŸ¥é‡è¤‡")
                
                # è¼‰å…¥å·²å­˜åœ¨çš„ Order No
                order_index_file = Path("data/review_history/bingx/metadata/order_index.json")
                existing_orders = set()
                
                if order_index_file.exists():
                    try:
                        with open(order_index_file, 'r', encoding='utf-8') as f:
                            index_data = json.load(f)
                            existing_orders = set(index_data.get('order_numbers', []))
                    except:
                        pass
                
                # æª¢æŸ¥ç•¶å‰æ–‡ä»¶ä¸­çš„ Order No
                current_orders = set(combined_df[order_no_col].astype(str).tolist())
                duplicate_orders = current_orders & existing_orders
                new_orders = current_orders - existing_orders
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric("æ–°è¨‚å–®", len(new_orders), delta="å°‡è¢«ä¿å­˜")
                
                with col2:
                    st.metric("é‡è¤‡è¨‚å–®", len(duplicate_orders), delta="å°‡è¢«è·³é", delta_color="inverse")
                
                if len(duplicate_orders) > 0:
                    with st.expander(f"æŸ¥çœ‹ {len(duplicate_orders)} å€‹é‡è¤‡çš„ Order No"):
                        st.write(list(duplicate_orders)[:20])
                        if len(duplicate_orders) > 20:
                            st.write(f"... é‚„æœ‰ {len(duplicate_orders) - 20} å€‹")
                
                # æ­¥é©Ÿ 5ï¼šè™•ç†é¸é …
                st.subheader("5ï¸âƒ£ è™•ç†é¸é …")
                
                duplicate_action = st.radio(
                    "é‡è¤‡è¨‚å–®è™•ç†æ–¹å¼",
                    ["è·³éé‡è¤‡ï¼ˆæ¨è–¦ï¼‰", "æ›´æ–°é‡è¤‡", "ä¿ç•™æ‰€æœ‰"],
                    help="è·³éï¼šåªä¿å­˜æ–°è¨‚å–® | æ›´æ–°ï¼šç”¨æ–°æ•¸æ“šè¦†è“‹ | ä¿ç•™æ‰€æœ‰ï¼šå…è¨±é‡è¤‡"
                )
                
                # æ­¥é©Ÿ 6ï¼šè½‰æ›ä¸¦ä¿å­˜
                st.subheader("6ï¸âƒ£ è½‰æ›ä¸¦ä¿å­˜")
                
                if st.button("ğŸ”„ è½‰æ›ä¸¦ä¿å­˜", type="primary"):
                    try:
                        with st.spinner("æ­£åœ¨è™•ç†..."):
                            # å‰µå»ºç›®éŒ„
                            base_dir = Path("data/review_history/bingx")
                            orders_dir = base_dir / "orders"
                            metadata_dir = base_dir / "metadata"
                            
                            orders_dir.mkdir(parents=True, exist_ok=True)
                            metadata_dir.mkdir(parents=True, exist_ok=True)
                            
                            # è™•ç†æ¯å€‹è¨‚å–®
                            saved_count = 0
                            skipped_count = 0
                            updated_count = 0
                            
                            # æŒ‰æ—¥æœŸåˆ†çµ„
                            if time_col:
                                combined_df['date'] = pd.to_datetime(combined_df[time_col], errors='coerce').dt.date
                                grouped = combined_df.groupby('date')
                            else:
                                # å¦‚æœæ²’æœ‰æ™‚é–“æ¬„ä½ï¼Œå…¨éƒ¨ä¿å­˜åˆ°ä¸€å€‹æ–‡ä»¶
                                grouped = [(datetime.now().date(), combined_df)]
                            
                            new_order_numbers = []
                            
                            for date, group in grouped:
                                if pd.isna(date):
                                    continue
                                
                                # æ–‡ä»¶è·¯å¾‘
                                year = date.year
                                month = f"{date.month:02d}"
                                day_file = f"{date.strftime('%Y%m%d')}.json"
                                
                                file_path = orders_dir / str(year) / month / day_file
                                file_path.parent.mkdir(parents=True, exist_ok=True)
                                
                                # è®€å–å·²å­˜åœ¨çš„æ•¸æ“š
                                existing_data = []
                                if file_path.exists():
                                    try:
                                        with open(file_path, 'r', encoding='utf-8') as f:
                                            existing_data = json.load(f)
                                    except:
                                        pass
                                
                                # è½‰æ›ç•¶å¤©çš„è¨‚å–®
                                day_orders = []
                                
                                for _, row in group.iterrows():
                                    order_no = str(row.get(order_no_col, ''))
                                    
                                    # æª¢æŸ¥é‡è¤‡
                                    if order_no in existing_orders:
                                        if "è·³é" in duplicate_action:
                                            skipped_count += 1
                                            continue
                                        elif "æ›´æ–°" in duplicate_action:
                                            # å¾å·²å­˜åœ¨æ•¸æ“šä¸­ç§»é™¤èˆŠçš„
                                            existing_data = [o for o in existing_data if o.get('order_no') != order_no]
                                            updated_count += 1
                                    
                                    # è½‰æ›ç‚ºæ¨™æº–æ ¼å¼
                                    order = {
                                        'order_no': order_no,
                                        'trade_id': f"bingx_{order_no}",
                                        'source': 'bingx',
                                        'account_type': str(row.get('account_type', '')),
                                        'symbol': str(row.get('symbol', '')),
                                        'side': str(row.get('side', '')),
                                        'open_time': str(row.get('openTime(UTC+8)', '')),
                                        'close_time': str(row.get('closeTime(UTC+8)', '')),
                                        'entry_price': float(row.get('openPrice', 0)),
                                        'exit_price': float(row.get('closePrice', 0)),
                                        'quantity': float(row.get('quantity', 0)),
                                        'leverage': float(row.get('leverage', 1)),
                                        'pnl': float(row.get('Realized PNL', 0)),
                                        'fee': float(row.get('fees', 0)),
                                        'uploaded_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                                        'file_source': uploaded_file.name
                                    }
                                    
                                    day_orders.append(order)
                                    new_order_numbers.append(order_no)
                                    saved_count += 1
                                
                                # åˆä½µä¸¦ä¿å­˜
                                if day_orders:
                                    all_day_orders = existing_data + day_orders
                                    
                                    with open(file_path, 'w', encoding='utf-8') as f:
                                        json.dump(all_day_orders, f, indent=2, ensure_ascii=False)
                            
                            # æ›´æ–°ç´¢å¼•
                            all_order_numbers = list(existing_orders | set(new_order_numbers))
                            
                            index_data = {
                                'order_numbers': all_order_numbers,
                                'total_orders': len(all_order_numbers),
                                'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                            }
                            
                            with open(order_index_file, 'w', encoding='utf-8') as f:
                                json.dump(index_data, f, indent=2, ensure_ascii=False)
                            
                            # é¡¯ç¤ºçµæœ
                            st.success("âœ… è½‰æ›å®Œæˆï¼")
                            
                            col1, col2, col3 = st.columns(3)
                            
                            with col1:
                                st.metric("å·²ä¿å­˜", saved_count)
                            
                            with col2:
                                st.metric("å·²è·³é", skipped_count)
                            
                            with col3:
                                st.metric("å·²æ›´æ–°", updated_count)
                            
                            st.info(f"ğŸ“ ä¿å­˜ä½ç½®ï¼š`data/review_history/bingx/orders/`")
                            st.info(f"ğŸ“‹ ç´¢å¼•å·²æ›´æ–°ï¼š{len(all_order_numbers)} å€‹ Order No")
                    
                    except Exception as e:
                        st.error(f"âŒ ä¿å­˜å¤±æ•—ï¼š{str(e)}")
                        import traceback
                        st.code(traceback.format_exc())
            
            except Exception as e:
                st.error(f"âŒ è®€å–æ–‡ä»¶å¤±æ•—ï¼š{str(e)}")
                import traceback
                st.code(traceback.format_exc())
        
        # æŸ¥çœ‹å·²ä¿å­˜çš„è¨˜éŒ„
        st.divider()
        st.subheader("ğŸ“‚ å·²ä¿å­˜çš„è¨˜éŒ„")
        
        orders_dir = Path("data/review_history/bingx/orders")
        
        if not orders_dir.exists():
            st.info("é‚„æ²’æœ‰ä¿å­˜ä»»ä½•è¨˜éŒ„")
        else:
            # çµ±è¨ˆæ–‡ä»¶
            order_files = list(orders_dir.rglob("*.json"))
            
            if not order_files:
                st.info("é‚„æ²’æœ‰ä¿å­˜ä»»ä½•è¨˜éŒ„")
            else:
                st.write(f"**ç¸½æ–‡ä»¶æ•¸**ï¼š{len(order_files)}")
                
                # è®€å–ç´¢å¼•
                order_index_file = Path("data/review_history/bingx/metadata/order_index.json")
                
                if order_index_file.exists():
                    try:
                        with open(order_index_file, 'r', encoding='utf-8') as f:
                            index_data = json.load(f)
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.metric("ç¸½è¨‚å–®æ•¸", index_data.get('total_orders', 0))
                        
                        with col2:
                            st.write(f"**æœ€å¾Œæ›´æ–°**")
                            st.write(index_data.get('last_updated', 'N/A'))
                    except:
                        pass
                
                # é¡¯ç¤ºæœ€è¿‘çš„æ–‡ä»¶
                st.write("**æœ€è¿‘çš„æ–‡ä»¶**ï¼ˆæœ€å¤šé¡¯ç¤º 10 å€‹ï¼‰ï¼š")
                
                recent_files = sorted(order_files, key=lambda x: x.stat().st_mtime, reverse=True)[:10]
                
                for file_path in recent_files:
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        
                        rel_path = file_path.relative_to(orders_dir)
                        st.write(f"- `{rel_path}` ({len(data)} ç­†è¨‚å–®)")
                    except:
                        pass
        st.subheader("ğŸ“ äº¤æ˜“è¨˜éŒ„ç®¡ç†")
        
        st.info("""
        **åŠŸèƒ½èªªæ˜**ï¼š
        - ä¸Šå‚³ BingX åŒ¯å‡ºçš„æ–‡ä»¶ï¼ˆExcel æˆ– CSVï¼‰
        - è‡ªå‹•è½‰æ›æˆçµ±ä¸€çš„ JSON æ ¼å¼
        - æ”¯æŒæŒ‰å¤©/é€±/æœˆåˆ†çµ„ä¿å­˜
        - ç›®å‰æ”¯æ´ï¼šBingXï¼ˆæœªä¾†å¯æ“´å±•å…¶ä»–äº¤æ˜“æ‰€ï¼‰
        """)
        
        # é¸æ“‡æ–‡ä»¶é¡å‹
        file_type = st.radio(
            "é¸æ“‡æ–‡ä»¶é¡å‹",
            ["Order_Historyï¼ˆè¨‚å–®è¨˜éŒ„ï¼‰", "Transaction_Historyï¼ˆè³‡é‡‘æµæ°´ï¼‰"]
        )
        
        # ä¸Šå‚³æ–‡ä»¶
        uploaded_file = st.file_uploader(
            "ä¸Šå‚³ BingX æ–‡ä»¶ï¼ˆExcel æˆ– CSVï¼‰",
            type=['xlsx', 'xls', 'csv'],
            help="å¾ BingX åŒ¯å‡ºçš„ Order_History æˆ– Transaction_History æ–‡ä»¶"
        )
        
        if uploaded_file is not None:
            try:
                # æª¢æ¸¬æ–‡ä»¶çš„çœŸå¯¦é¡å‹ï¼ˆä¸åªçœ‹å‰¯æª”åï¼‰
                uploaded_file.seek(0)
                file_header = uploaded_file.read(4)
                uploaded_file.seek(0)
                
                # åˆ¤æ–·æ˜¯å¦ç‚º ZIP/Excel æ ¼å¼ï¼ˆPK é–‹é ­ï¼‰
                is_excel = file_header[:2] == b'PK'
                
                file_extension = uploaded_file.name.split('.')[-1].lower()
                
                # å¦‚æœæ–‡ä»¶é ­æ˜¯ PKï¼Œå¼·åˆ¶ç•¶ä½œ Excel è™•ç†
                if is_excel:
                    st.info(f"ğŸ“Œ æª¢æ¸¬åˆ°æ–‡ä»¶å¯¦éš›ç‚º Excel æ ¼å¼ï¼ˆå³ä½¿å‰¯æª”åæ˜¯ .{file_extension}ï¼‰")
                    file_extension = 'xlsx'
                
                # æ ¹æ“šæ–‡ä»¶é¡å‹è®€å–
                if file_extension == 'csv':
                    # CSV æ ¼å¼ï¼ˆå–®ä¸€å·¥ä½œè¡¨ï¼‰
                    # å˜—è©¦å¤šç¨®ç·¨ç¢¼
                    encodings = ['utf-8', 'utf-8-sig', 'big5', 'gb2312', 'gbk', 'gb18030', 'latin1', 'cp1252', 'iso-8859-1']
                    df = None
                    used_encoding = None
                    last_error = None
                    
                    for encoding in encodings:
                        try:
                            uploaded_file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é‡
                            df = pd.read_csv(uploaded_file, encoding=encoding)
                            used_encoding = encoding
                            break
                        except (UnicodeDecodeError, UnicodeError) as e:
                            last_error = str(e)
                            continue
                        except Exception as e:
                            last_error = str(e)
                            continue
                    
                    if df is None:
                        st.error("âŒ ç„¡æ³•è®€å– CSV æ–‡ä»¶ï¼Œå˜—è©¦äº†å¤šç¨®ç·¨ç¢¼éƒ½å¤±æ•—")
                        st.info("æ”¯æŒçš„ç·¨ç¢¼ï¼šUTF-8, Big5, GB2312, GBK, GB18030, Latin1, CP1252")
                        if last_error:
                            st.code(f"æœ€å¾Œçš„éŒ¯èª¤ï¼š{last_error}")
                        
                        # æä¾›æ‰‹å‹•é¸æ“‡ç·¨ç¢¼çš„é¸é …
                        st.write("---")
                        st.write("**æ‰‹å‹•é¸æ“‡ç·¨ç¢¼**ï¼š")
                        manual_encoding = st.selectbox(
                            "é¸æ“‡ç·¨ç¢¼",
                            ['utf-8', 'utf-8-sig', 'big5', 'gb2312', 'gbk', 'gb18030', 'latin1', 'cp1252', 'iso-8859-1', 'shift-jis', 'euc-kr']
                        )
                        
                        if st.button("ä½¿ç”¨é¸æ“‡çš„ç·¨ç¢¼é‡è©¦"):
                            try:
                                uploaded_file.seek(0)
                                df = pd.read_csv(uploaded_file, encoding=manual_encoding)
                                used_encoding = manual_encoding
                                st.success(f"âœ… ä½¿ç”¨ {manual_encoding} ç·¨ç¢¼æˆåŠŸï¼")
                            except Exception as e:
                                st.error(f"âŒ ä½¿ç”¨ {manual_encoding} ç·¨ç¢¼å¤±æ•—ï¼š{str(e)}")
                        
                        all_data = None  # è¨­ç½®ç‚º None é¿å…å¾ŒçºŒéŒ¯èª¤
                    else:
                        st.success(f"âœ… æˆåŠŸè¼‰å…¥ CSV æ–‡ä»¶ï¼š{uploaded_file.name}")
                        st.caption(f"ä½¿ç”¨ç·¨ç¢¼ï¼š{used_encoding}")
                        st.write(f"**è¨˜éŒ„æ•¸**ï¼š{len(df)}")
                        
                        # æ·»åŠ å¸³æˆ¶é¡å‹æ¨™è¨˜ï¼ˆå¾æ–‡ä»¶åæ¨æ–·ï¼‰
                        if 'Standard' in uploaded_file.name or 'standard' in uploaded_file.name:
                            df['account_type'] = 'Standard_Futures'
                        elif 'Perpetual' in uploaded_file.name or 'perpetual' in uploaded_file.name or 'USDâ“ˆ' in uploaded_file.name:
                            df['account_type'] = 'USDâ“¢_M_Perpetual_Futures'
                        elif 'Fund' in uploaded_file.name or 'fund' in uploaded_file.name:
                            df['account_type'] = 'Fund_Account'
                        else:
                            df['account_type'] = 'Unknown'
                        
                        all_data = [df]
                        combined_df = df
                        tab_summary = [{
                            'ä¾†æº': 'CSV',
                            'è¨˜éŒ„æ•¸': len(df),
                            'å¸³æˆ¶é¡å‹': df['account_type'].iloc[0] if len(df) > 0 else 'Unknown'
                        }]
                
                else:
                    # Excel æ ¼å¼ï¼ˆå¯èƒ½æœ‰å¤šå€‹å·¥ä½œè¡¨ï¼‰
                    xl = pd.ExcelFile(uploaded_file)
                    
                    st.success(f"âœ… æˆåŠŸè¼‰å…¥ Excel æ–‡ä»¶ï¼š{uploaded_file.name}")
                    st.write(f"**å·¥ä½œè¡¨æ•¸é‡**ï¼š{len(xl.sheet_names)}")
                    st.write(f"**å·¥ä½œè¡¨åç¨±**ï¼š{', '.join(xl.sheet_names)}")
                    
                    # è®€å–æ‰€æœ‰ tabs
                    all_data = []
                    tab_summary = []
                    
                    for sheet_name in xl.sheet_names:
                        df = pd.read_excel(uploaded_file, sheet_name=sheet_name)
                        if len(df) > 0:
                            df['account_type'] = sheet_name  # æ·»åŠ å¸³æˆ¶é¡å‹æ¨™è¨˜
                            all_data.append(df)
                            tab_summary.append({
                                'å·¥ä½œè¡¨': sheet_name,
                                'è¨˜éŒ„æ•¸': len(df)
                            })
                    
                    if not all_data:
                        st.warning("âš ï¸ æ‰€æœ‰å·¥ä½œè¡¨éƒ½æ˜¯ç©ºçš„")
                        all_data = None
                    else:
                        # åˆä½µæ‰€æœ‰æ•¸æ“š
                        combined_df = pd.concat(all_data, ignore_index=True)
                
                if all_data:
                    # é¡¯ç¤ºæ‘˜è¦
                    st.subheader("ğŸ“Š æ•¸æ“šæ‘˜è¦")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write(f"**ç¸½è¨˜éŒ„æ•¸**ï¼š{len(combined_df)}")
                        st.write(f"**æ¬„ä½æ•¸**ï¼š{len(combined_df.columns)}")
                    
                    with col2:
                        summary_df = pd.DataFrame(tab_summary)
                        st.dataframe(summary_df, use_container_width=True)
                    
                    # é¡¯ç¤ºæ•¸æ“šé è¦½
                    st.subheader("ğŸ“‹ æ•¸æ“šé è¦½ï¼ˆå‰ 10 ç­†ï¼‰")
                    st.dataframe(combined_df.head(10), use_container_width=True)
                    
                    # è½‰æ›é¸é …
                    st.divider()
                    st.subheader("ğŸ”„ è½‰æ›ç‚ºæ¨™æº–æ ¼å¼")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        save_format = st.selectbox(
                            "ä¿å­˜æ ¼å¼",
                            ["æŒ‰å¤©åˆ†çµ„", "æŒ‰é€±åˆ†çµ„", "æŒ‰æœˆåˆ†çµ„", "å…¨éƒ¨ä¿å­˜åˆ°ä¸€å€‹æ–‡ä»¶"]
                        )
                    
                    with col2:
                        st.write("**æ¨™æº– JSON æ ¼å¼åŒ…å«**ï¼š")
                        if "Order_History" in file_type:
                            st.write("- date, symbol, side")
                            st.write("- entry_price, exit_price")
                            st.write("- quantity, pnl, fee")
                            st.write("- account_type, leverage")
                        else:
                            st.write("- date, type, asset")
                            st.write("- amount, balance")
                            st.write("- account_type, info")
                    
                    if st.button("ğŸ”„ è½‰æ›ä¸¦ä¿å­˜", type="primary"):
                        try:
                            # å‰µå»ºç›®éŒ„
                            review_dir = Path("data/review_history")
                            review_dir.mkdir(parents=True, exist_ok=True)
                            
                            # æ ¹æ“šæ–‡ä»¶é¡å‹è½‰æ›
                            if "Order_History" in file_type:
                                # è¨‚å–®è¨˜éŒ„æ ¼å¼
                                trades_list = []
                                
                                for _, row in combined_df.iterrows():
                                    trade = {
                                        'date': str(row.get('closeTime(UTC+8)', row.get('openTime(UTC+8)', ''))),
                                        'symbol': str(row.get('symbol', '')),
                                        'side': str(row.get('side', '')),
                                        'entry_price': float(row.get('openPrice', 0)),
                                        'exit_price': float(row.get('closePrice', 0)),
                                        'quantity': float(row.get('quantity', 0)),
                                        'pnl': float(row.get('Realized PNL', 0)),
                                        'fee': float(row.get('fees', 0)),
                                        'account_type': str(row.get('account_type', '')),
                                        'leverage': float(row.get('leverage', 1)),
                                        'open_time': str(row.get('openTime(UTC+8)', '')),
                                        'close_time': str(row.get('closeTime(UTC+8)', ''))
                                    }
                                    trades_list.append(trade)
                            
                            else:
                                # è³‡é‡‘æµæ°´æ ¼å¼
                                trades_list = []
                                
                                for _, row in combined_df.iterrows():
                                    trade = {
                                        'date': str(row.get('time(UTC+8)', '')),
                                        'type': str(row.get('type', '')),
                                        'asset': str(row.get('asset', '')),
                                        'amount': float(row.get('amount', 0)),
                                        'balance': float(row.get('balance', 0)),
                                        'account_type': str(row.get('account_type', '')),
                                        'info': str(row.get('info', ''))
                                    }
                                    trades_list.append(trade)
                            
                            # ä¿å­˜æ–‡ä»¶
                            if save_format == "å…¨éƒ¨ä¿å­˜åˆ°ä¸€å€‹æ–‡ä»¶":
                                # ä¿å­˜æ‰€æœ‰è¨˜éŒ„åˆ°ä¸€å€‹æ–‡ä»¶
                                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                                file_prefix = "orders" if "Order_History" in file_type else "transactions"
                                output_file = review_dir / f"{file_prefix}_bingx_{timestamp}.json"
                                
                                with open(output_file, 'w', encoding='utf-8') as f:
                                    json.dump(trades_list, f, indent=2, ensure_ascii=False)
                                
                                st.success(f"âœ… å·²ä¿å­˜ {len(trades_list)} ç­†è¨˜éŒ„åˆ°ï¼š")
                                st.code(str(output_file))
                            
                            else:
                                # æŒ‰æ™‚é–“åˆ†çµ„ä¿å­˜
                                if "Order_History" in file_type:
                                    time_col = 'close_time'
                                else:
                                    time_col = 'date'
                                
                                # è½‰æ›ç‚º DataFrame ä»¥ä¾¿åˆ†çµ„
                                trades_df = pd.DataFrame(trades_list)
                                trades_df['datetime'] = pd.to_datetime(trades_df[time_col], errors='coerce')
                                
                                # ç§»é™¤ç„¡æ•ˆæ—¥æœŸ
                                trades_df = trades_df.dropna(subset=['datetime'])
                                
                                if len(trades_df) == 0:
                                    st.error("âŒ ç„¡æ³•è§£ææ—¥æœŸï¼Œè«‹æª¢æŸ¥æ•¸æ“šæ ¼å¼")
                                else:
                                    if save_format == "æŒ‰å¤©åˆ†çµ„":
                                        trades_df['period'] = trades_df['datetime'].dt.date
                                    elif save_format == "æŒ‰é€±åˆ†çµ„":
                                        trades_df['period'] = trades_df['datetime'].dt.to_period('W')
                                    else:  # æŒ‰æœˆåˆ†çµ„
                                        trades_df['period'] = trades_df['datetime'].dt.to_period('M')
                                    
                                    # åˆ†çµ„ä¿å­˜
                                    saved_files = []
                                    for period, group in trades_df.groupby('period'):
                                        period_trades = group.drop(['datetime', 'period'], axis=1).to_dict('records')
                                        
                                        file_prefix = "orders" if "Order_History" in file_type else "transactions"
                                        output_file = review_dir / f"{file_prefix}_bingx_{period}.json"
                                        
                                        with open(output_file, 'w', encoding='utf-8') as f:
                                            json.dump(period_trades, f, indent=2, ensure_ascii=False)
                                        
                                        saved_files.append({
                                            'æ–‡ä»¶': output_file.name,
                                            'è¨˜éŒ„æ•¸': len(period_trades)
                                        })
                                    
                                    st.success(f"âœ… å·²ä¿å­˜ {len(saved_files)} å€‹æ–‡ä»¶ï¼š")
                                    st.dataframe(pd.DataFrame(saved_files), use_container_width=True)
                            
                            # é¡¯ç¤ºç¤ºä¾‹æ•¸æ“š
                            st.subheader("ğŸ“„ è½‰æ›å¾Œçš„æ ¼å¼ç¤ºä¾‹")
                            st.json(trades_list[0] if trades_list else {})
                        
                        except Exception as e:
                            st.error(f"âŒ è½‰æ›å¤±æ•—ï¼š{str(e)}")
                            import traceback
                            st.code(traceback.format_exc())
            
            except Exception as e:
                st.error(f"âŒ è®€å–æ–‡ä»¶å¤±æ•—ï¼š{str(e)}")
                import traceback
                st.code(traceback.format_exc())
        
        # æŸ¥çœ‹å·²ä¿å­˜çš„è¨˜éŒ„
        st.divider()
        st.subheader("ğŸ“‚ å·²ä¿å­˜çš„è¨˜éŒ„")
        
        review_dir = Path("data/review_history")
        
        if not review_dir.exists():
            st.info("é‚„æ²’æœ‰ä¿å­˜ä»»ä½•è¨˜éŒ„")
        else:
            # æŸ¥æ‰¾æ‰€æœ‰è¨˜éŒ„æ–‡ä»¶
            order_files = list(review_dir.glob("orders_bingx_*.json"))
            trans_files = list(review_dir.glob("transactions_bingx_*.json"))
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**è¨‚å–®è¨˜éŒ„**ï¼š{len(order_files)} å€‹æ–‡ä»¶")
                if order_files:
                    for f in sorted(order_files, reverse=True)[:5]:
                        st.write(f"- {f.name}")
            
            with col2:
                st.write(f"**è³‡é‡‘æµæ°´**ï¼š{len(trans_files)} å€‹æ–‡ä»¶")
                if trans_files:
                    for f in sorted(trans_files, reverse=True)[:5]:
                        st.write(f"- {f.name}")
            
            # æŸ¥çœ‹æ–‡ä»¶å…§å®¹
            all_files = order_files + trans_files
            
            if all_files:
                st.write("---")
                selected_file = st.selectbox(
                    "é¸æ“‡æ–‡ä»¶æŸ¥çœ‹å…§å®¹",
                    sorted(all_files, reverse=True),
                    format_func=lambda x: x.name
                )
                
                if selected_file:
                    try:
                        with open(selected_file, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        
                        st.write(f"**è¨˜éŒ„æ•¸**ï¼š{len(data)}")
                        
                        # è½‰æ›ç‚º DataFrame é¡¯ç¤º
                        df = pd.DataFrame(data)
                        st.dataframe(df, use_container_width=True, height=300)
                        
                        # ä¸‹è¼‰æŒ‰éˆ•
                        csv = df.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è¼‰ CSV",
                            data=csv,
                            file_name=f"{selected_file.stem}.csv",
                            mime="text/csv"
                        )
                    
                    except Exception as e:
                        st.error(f"âŒ è®€å–å¤±æ•—ï¼š{str(e)}")
    
    elif sub_function == "åŸ·è¡Œè³ªé‡è©•åˆ†":
        st.subheader("â­ åŸ·è¡Œè³ªé‡è©•åˆ†")
        
        # æª¢æŸ¥è³ªé‡è©•åˆ†è¨˜éŒ„
        quality_file = Path("data/review_history/quality_scores.json")
        
        if not quality_file.exists():
            st.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°è³ªé‡è©•åˆ†è¨˜éŒ„")
            st.info("""
            **åŸ·è¡Œè³ªé‡è©•åˆ†**ç”¨æ–¼è©•ä¼°äº¤æ˜“åŸ·è¡Œçš„è³ªé‡ï¼ŒåŒ…æ‹¬ï¼š
            - é€²å ´æ™‚æ©Ÿ
            - å‡ºå ´æ™‚æ©Ÿ
            - é¢¨éšªç®¡ç†
            - ç´€å¾‹éµå®ˆ
            
            ä½¿ç”¨è¦†ç›¤ç³»çµ±ä¾†è¨˜éŒ„å’Œè©•åˆ†ï¼š
            ```python
            python3 example_review_system.py
            ```
            """)
        else:
            try:
                with open(quality_file, 'r', encoding='utf-8') as f:
                    scores = json.load(f)
                
                if not scores:
                    st.info("âœ… ç›®å‰æ²’æœ‰è³ªé‡è©•åˆ†è¨˜éŒ„")
                else:
                    st.write(f"**ç¸½è©•åˆ†è¨˜éŒ„æ•¸**ï¼š{len(scores)}")
                    
                    # è½‰æ›ç‚º DataFrame
                    scores_df = pd.DataFrame(scores)
                    
                    # è¨ˆç®—å¹³å‡åˆ†
                    if 'total_score' in scores_df.columns:
                        avg_score = scores_df['total_score'].mean()
                        
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("å¹³å‡ç¸½åˆ†", f"{avg_score:.2f}")
                        
                        with col2:
                            if 'entry_score' in scores_df.columns:
                                avg_entry = scores_df['entry_score'].mean()
                                st.metric("å¹³å‡é€²å ´åˆ†", f"{avg_entry:.2f}")
                        
                        with col3:
                            if 'exit_score' in scores_df.columns:
                                avg_exit = scores_df['exit_score'].mean()
                                st.metric("å¹³å‡å‡ºå ´åˆ†", f"{avg_exit:.2f}")
                    
                    # é¡¯ç¤ºè©•åˆ†åˆ—è¡¨
                    st.subheader("ğŸ“Š è©•åˆ†åˆ—è¡¨")
                    st.dataframe(scores_df, use_container_width=True, height=400)
                    
                    # è©•åˆ†è¶¨å‹¢åœ–
                    if 'date' in scores_df.columns and 'total_score' in scores_df.columns:
                        st.subheader("ğŸ“ˆ è©•åˆ†è¶¨å‹¢")
                        fig = px.line(scores_df, x='date', y='total_score',
                                     title='åŸ·è¡Œè³ªé‡è©•åˆ†è¶¨å‹¢',
                                     labels={'date': 'æ—¥æœŸ', 'total_score': 'ç¸½åˆ†'})
                        st.plotly_chart(fig, use_container_width=True)
            
            except Exception as e:
                st.error(f"âŒ è®€å–è³ªé‡è©•åˆ†å¤±æ•—ï¼š{str(e)}")
    
    else:  # è¦†ç›¤å ±å‘Š
        st.subheader("ğŸ“„ è¦†ç›¤å ±å‘Š")
        
        # æª¢æŸ¥å ±å‘Šæ–‡ä»¶
        reports_dir = Path("data/review_history/reports")
        
        if not reports_dir.exists():
            st.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°è¦†ç›¤å ±å‘Š")
            st.info("""
            **è¦†ç›¤å ±å‘Š**åŒ…å«ï¼š
            - æ¯æ—¥/é€±/æœˆäº¤æ˜“ç¸½çµ
            - ç¸¾æ•ˆåˆ†æ
            - æ”¹é€²å»ºè­°
            - æŠ€èƒ½è¿½è¹¤
            
            ä½¿ç”¨è¦†ç›¤ç³»çµ±ç”Ÿæˆå ±å‘Šï¼š
            ```python
            python3 example_review_system.py
            ```
            """)
        else:
            report_files = list(reports_dir.glob("*.json"))
            
            if not report_files:
                st.info("âœ… ç›®å‰æ²’æœ‰è¦†ç›¤å ±å‘Š")
            else:
                st.write(f"**å ±å‘Šæ•¸é‡**ï¼š{len(report_files)}")
                
                # é¸æ“‡å ±å‘Š
                selected_report = st.selectbox(
                    "é¸æ“‡å ±å‘Š",
                    report_files,
                    format_func=lambda x: x.stem
                )
                
                # è®€å–å ±å‘Š
                try:
                    with open(selected_report, 'r', encoding='utf-8') as f:
                        report = json.load(f)
                    
                    # é¡¯ç¤ºå ±å‘Šä¿¡æ¯
                    st.subheader("ğŸ“‹ å ±å‘Šä¿¡æ¯")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write(f"**å ±å‘Šé¡å‹**ï¼š{report.get('type', 'N/A')}")
                        st.write(f"**æ™‚é–“ç¯„åœ**ï¼š{report.get('start_date', 'N/A')} è‡³ {report.get('end_date', 'N/A')}")
                    
                    with col2:
                        st.write(f"**ç¸½äº¤æ˜“æ•¸**ï¼š{report.get('total_trades', 0)}")
                        st.write(f"**å‹ç‡**ï¼š{report.get('win_rate', 0):.2f}%")
                    
                    # é¡¯ç¤ºç¸¾æ•ˆæŒ‡æ¨™
                    if 'performance' in report:
                        st.subheader("ğŸ“ˆ ç¸¾æ•ˆæŒ‡æ¨™")
                        perf = report['performance']
                        
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.write(f"**ç¸½æç›Š**ï¼š{perf.get('total_pnl', 0):.2f} USDT")
                            st.write(f"**å¹³å‡ç²åˆ©**ï¼š{perf.get('avg_win', 0):.2f} USDT")
                        
                        with col2:
                            st.write(f"**å¹³å‡è™§æ**ï¼š{perf.get('avg_loss', 0):.2f} USDT")
                            st.write(f"**ç²åˆ©å› å­**ï¼š{perf.get('profit_factor', 0):.2f}")
                        
                        with col3:
                            st.write(f"**æœ€å¤§å›æ’¤**ï¼š{perf.get('max_drawdown', 0):.2f}%")
                            st.write(f"**å¤æ™®æ¯”ç‡**ï¼š{perf.get('sharpe_ratio', 0):.2f}")
                    
                    # é¡¯ç¤ºæ”¹é€²å»ºè­°
                    if 'recommendations' in report:
                        st.subheader("ğŸ’¡ æ”¹é€²å»ºè­°")
                        for rec in report['recommendations']:
                            st.write(f"- {rec}")
                    
                    # é¡¯ç¤ºå®Œæ•´å ±å‘Š
                    with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´å ±å‘Šï¼ˆJSONï¼‰"):
                        st.json(report)
                
                except Exception as e:
                    st.error(f"âŒ è®€å–å ±å‘Šå¤±æ•—ï¼š{str(e)}")

# ==================== 7. ç­–ç•¥ç®¡ç† ====================
elif category == "7ï¸âƒ£ ç­–ç•¥ç®¡ç†":
    st.header("âš™ï¸ ç­–ç•¥ç®¡ç†")
    
    sub_function = st.sidebar.selectbox(
        "é¸æ“‡åŠŸèƒ½",
        [
            "ç­–ç•¥åˆ—è¡¨",
            "ç­–ç•¥é…ç½®æŸ¥çœ‹",
            "ç­–ç•¥å•Ÿç”¨/ç¦ç”¨",
            "ç­–ç•¥ç‰ˆæœ¬ç®¡ç†"
        ]
    )
    
    if sub_function == "ç­–ç•¥å•Ÿç”¨/ç¦ç”¨":
        st.subheader("âš™ï¸ ç­–ç•¥å•Ÿç”¨/ç¦ç”¨")
        
        strategy_files = glob.glob('strategies/*.json')
        
        if not strategy_files:
            st.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°ç­–ç•¥é…ç½®æ–‡ä»¶")
        else:
            st.write("**æ‰€æœ‰ç­–ç•¥ç‹€æ…‹**")
            
            # è®€å–æ‰€æœ‰ç­–ç•¥ç‹€æ…‹
            strategies_status = []
            
            for strategy_file in strategy_files:
                with open(strategy_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                
                strategies_status.append({
                    'file': strategy_file,
                    'name': config.get('name', 'Unknown'),
                    'id': config.get('id', 'unknown'),
                    'enabled': config.get('enabled', False),
                    'version': config.get('version', '1.0.0')
                })
            
            # é¡¯ç¤ºç­–ç•¥åˆ—è¡¨
            for i, strategy in enumerate(strategies_status):
                col1, col2, col3, col4 = st.columns([3, 2, 1, 2])
                
                with col1:
                    st.write(f"**{strategy['name']}**")
                    st.caption(f"ID: {strategy['id']}")
                
                with col2:
                    st.write(f"ç‰ˆæœ¬: {strategy['version']}")
                
                with col3:
                    if strategy['enabled']:
                        st.success("âœ… å•Ÿç”¨")
                    else:
                        st.error("âŒ ç¦ç”¨")
                
                with col4:
                    # åˆ‡æ›æŒ‰éˆ•
                    new_status = st.checkbox(
                        "å•Ÿç”¨" if not strategy['enabled'] else "ç¦ç”¨",
                        key=f"toggle_{i}",
                        value=strategy['enabled']
                    )
                    
                    # å¦‚æœç‹€æ…‹æ”¹è®Šï¼Œæ›´æ–°é…ç½®æ–‡ä»¶
                    if new_status != strategy['enabled']:
                        try:
                            with open(strategy['file'], 'r', encoding='utf-8') as f:
                                config = json.load(f)
                            
                            config['enabled'] = new_status
                            
                            with open(strategy['file'], 'w', encoding='utf-8') as f:
                                json.dump(config, f, indent=2, ensure_ascii=False)
                            
                            st.success(f"âœ… å·²{'å•Ÿç”¨' if new_status else 'ç¦ç”¨'}ç­–ç•¥ï¼š{strategy['name']}")
                            st.rerun()
                        
                        except Exception as e:
                            st.error(f"âŒ æ›´æ–°å¤±æ•—ï¼š{str(e)}")
                
                st.divider()
    
    elif sub_function == "ç­–ç•¥åˆ—è¡¨" or sub_function == "ç­–ç•¥é…ç½®æŸ¥çœ‹":
        st.subheader("ğŸ“‹ ç­–ç•¥é…ç½®")
        
        strategy_files = glob.glob('strategies/*.json')
        
        if not strategy_files:
            st.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°ç­–ç•¥é…ç½®æ–‡ä»¶")
        else:
            selected_strategy = st.selectbox(
                "é¸æ“‡ç­–ç•¥",
                strategy_files,
                format_func=lambda x: x.replace('strategies/', '').replace('.json', '')
            )
            
            with open(selected_strategy, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            st.subheader("ğŸ“‹ åŸºæœ¬ä¿¡æ¯")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**ç­–ç•¥åç¨±**ï¼š{config.get('name', 'Unknown')}")
                st.write(f"**ç­–ç•¥ ID**ï¼š{config.get('id', 'unknown')}")
                st.write(f"**ç­–ç•¥é¡å‹**ï¼š{config.get('class', 'Unknown')}")
            
            with col2:
                status = "âœ… å•Ÿç”¨" if config.get('enabled', False) else "âŒ ç¦ç”¨"
                st.write(f"**ç‹€æ…‹**ï¼š{status}")
                st.write(f"**ç‰ˆæœ¬**ï¼š{config.get('version', '1.0.0')}")
            
            if 'parameters' in config:
                st.subheader("ğŸ›ï¸ ç­–ç•¥åƒæ•¸")
                params = config['parameters']
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.write("**æŠ€è¡“æŒ‡æ¨™**")
                    st.write(f"- EMA çŸ­æœŸï¼š{params.get('ema_short', 'N/A')}")
                    st.write(f"- EMA é•·æœŸï¼š{params.get('ema_long', 'N/A')}")
                    st.write(f"- RSI é€±æœŸï¼š{params.get('rsi_period', 'N/A')}")
                    st.write(f"- ATR é€±æœŸï¼š{params.get('atr_period', 'N/A')}")
                
                with col2:
                    st.write("**é€²å‡ºå ´**")
                    st.write(f"- æ­¢æï¼š{params.get('stop_loss_atr', 'N/A')} ATR")
                    st.write(f"- ç›®æ¨™ï¼š{params.get('take_profit_atr', 'N/A')} ATR")
                    st.write(f"- RSI è¶…è³£ï¼š{params.get('rsi_oversold', 'N/A')}")
                    st.write(f"- RSI è¶…è²·ï¼š{params.get('rsi_overbought', 'N/A')}")
                
                with col3:
                    st.write("**é€±æœŸ**")
                    timeframes = params.get('timeframes', [])
                    for tf in timeframes:
                        st.write(f"- {tf}")
            
            with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´é…ç½®ï¼ˆJSONï¼‰"):
                st.json(config)

# ==================== 8. é¢¨éšªç®¡ç† ====================
elif category == "8ï¸âƒ£ é¢¨éšªç®¡ç†":
    st.header("âš ï¸ é¢¨éšªç®¡ç†")
    
    sub_function = st.sidebar.selectbox(
        "é¸æ“‡åŠŸèƒ½",
        [
            "å…¨å±€é¢¨éšªè¨­ç½®",
            "ç­–ç•¥ç´šé¢¨éšªè¨­ç½®",
            "é¢¨éšªäº‹ä»¶è¨˜éŒ„"
        ]
    )
    
    if sub_function == "å…¨å±€é¢¨éšªè¨­ç½®":
        st.subheader("ğŸ›¡ï¸ å…¨å±€é¢¨éšªè¨­ç½®")
        
        try:
            import yaml
            with open('system_config.yaml', 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            risk_config = config.get('risk', {})
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**å…¨å±€é™åˆ¶**")
                st.write(f"- æœ€å¤§å›æ’¤ï¼š{risk_config.get('global_max_drawdown', 0)*100:.0f}%")
                st.write(f"- æ¯æ—¥è™§æé™åˆ¶ï¼š{risk_config.get('daily_loss_limit', 0)*100:.0f}%")
                st.write(f"- æœ€å¤§å€‰ä½ï¼š{risk_config.get('global_max_position', 0)*100:.0f}%")
            
            with col2:
                st.write("**ç­–ç•¥é»˜èªå€¼**")
                st.write(f"- å–®ç­–ç•¥æœ€å¤§å€‰ä½ï¼š{risk_config.get('default_max_position_per_strategy', 0)*100:.0f}%")
                st.write(f"- æ¯æ—¥æœ€å¤§äº¤æ˜“æ•¸ï¼š{risk_config.get('default_max_trades_per_day', 0)}")
                st.write(f"- æœ€å¤§é€£æï¼š{risk_config.get('default_max_consecutive_losses', 0)}")
            
            with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´é¢¨éšªé…ç½®"):
                st.json(risk_config)
        
        except Exception as e:
            st.error(f"âŒ è®€å–é…ç½®å¤±æ•—ï¼š{str(e)}")

# ==================== 9. æ•¸æ“šç®¡ç† ====================
elif category == "9ï¸âƒ£ æ•¸æ“šç®¡ç†":
    st.header("ğŸ’¾ æ•¸æ“šç®¡ç†")
    
    sub_function = st.sidebar.selectbox(
        "é¸æ“‡åŠŸèƒ½",
        [
            "æ•¸æ“šæºè¨­ç½®",
            "æ­·å²æ•¸æ“šä¸‹è¼‰",
            "æ•¸æ“šé©—è­‰"
        ]
    )
    
    if sub_function == "æ•¸æ“šæºè¨­ç½®":
        st.subheader("ğŸŒ æ•¸æ“šæºè¨­ç½®")
        
        try:
            import yaml
            with open('system_config.yaml', 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            data_config = config.get('data', {})
            
            st.write(f"**ä¸»æ•¸æ“šæº**ï¼š{data_config.get('primary_source', 'N/A')}")
            st.write(f"**å‚™ç”¨æ•¸æ“šæº**ï¼š{', '.join(data_config.get('backup_sources', []))}")
            st.write(f"**ç·©å­˜æ™‚é–“**ï¼š{data_config.get('cache_ttl', 0)} ç§’")
            
            with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´æ•¸æ“šé…ç½®"):
                st.json(data_config)
        
        except Exception as e:
            st.error(f"âŒ è®€å–é…ç½®å¤±æ•—ï¼š{str(e)}")
    
    elif sub_function == "æ­·å²æ•¸æ“šä¸‹è¼‰":
        st.subheader("ğŸ“¥ æ­·å²æ•¸æ“šä¸‹è¼‰")
        st.info("ğŸ’¡ æ•¸æ“šä¸‹è¼‰éœ€è¦é€šéå‘½ä»¤è¡Œï¼š")
        st.code("python3 fetch_market_data.py")

# ==================== 10. ç³»çµ±é…ç½® ====================
elif category == "ğŸ”Ÿ ç³»çµ±é…ç½®":
    st.header("ğŸ”§ ç³»çµ±é…ç½®")
    
    sub_function = st.sidebar.selectbox(
        "é¸æ“‡åŠŸèƒ½",
        [
            "ç³»çµ±ä¿¡æ¯",
            "å›æ¸¬é…ç½®",
            "é€šçŸ¥é…ç½®",
            "æ—¥èªŒé…ç½®"
        ]
    )
    
    try:
        import yaml
        with open('system_config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        if sub_function == "ç³»çµ±ä¿¡æ¯":
            st.subheader("â„¹ï¸ ç³»çµ±ä¿¡æ¯")
            system_config = config.get('system', {})
            
            st.write(f"**ç³»çµ±åç¨±**ï¼š{system_config.get('name', 'N/A')}")
            st.write(f"**ç‰ˆæœ¬**ï¼š{system_config.get('version', 'N/A')}")
            st.write(f"**ç’°å¢ƒ**ï¼š{system_config.get('environment', 'N/A')}")
        
        elif sub_function == "å›æ¸¬é…ç½®":
            st.subheader("ğŸ“Š å›æ¸¬é…ç½®")
            backtest_config = config.get('backtest', {})
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**æ‰‹çºŒè²»**ï¼š{backtest_config.get('commission', 0)*100:.2f}%")
                st.write(f"**æ»‘é»**ï¼š{backtest_config.get('slippage', 0)*100:.2f}%")
            
            with col2:
                st.write(f"**åˆå§‹è³‡é‡‘**ï¼š{backtest_config.get('initial_capital', 0):.0f} USDT")
                st.write(f"**ç„¡é¢¨éšªåˆ©ç‡**ï¼š{backtest_config.get('risk_free_rate', 0)*100:.0f}%")
            
            with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´å›æ¸¬é…ç½®"):
                st.json(backtest_config)
        
        elif sub_function == "é€šçŸ¥é…ç½®":
            st.subheader("ğŸ“¢ é€šçŸ¥é…ç½®")
            notif_config = config.get('notifications', {})
            
            telegram = notif_config.get('telegram', {})
            st.write(f"**Telegram**ï¼š{'âœ… å•Ÿç”¨' if telegram.get('enabled', False) else 'âŒ ç¦ç”¨'}")
            
            email = notif_config.get('email', {})
            st.write(f"**Email**ï¼š{'âœ… å•Ÿç”¨' if email.get('enabled', False) else 'âŒ ç¦ç”¨'}")
            
            webhook = notif_config.get('webhook', {})
            st.write(f"**Webhook**ï¼š{'âœ… å•Ÿç”¨' if webhook.get('enabled', False) else 'âŒ ç¦ç”¨'}")
        
        elif sub_function == "æ—¥èªŒé…ç½®":
            st.subheader("ğŸ“ æ—¥èªŒé…ç½®")
            logging_config = config.get('logging', {})
            
            st.write(f"**æ—¥èªŒç´šåˆ¥**ï¼š{logging_config.get('level', 'N/A')}")
            st.write(f"**æ—¥èªŒæ–‡ä»¶**ï¼š{logging_config.get('file', 'N/A')}")
            st.write(f"**æœ€å¤§å¤§å°**ï¼š{logging_config.get('max_bytes', 0) / 1024 / 1024:.0f} MB")
            st.write(f"**å‚™ä»½æ•¸é‡**ï¼š{logging_config.get('backup_count', 0)}")
    
    except Exception as e:
        st.error(f"âŒ è®€å–é…ç½®å¤±æ•—ï¼š{str(e)}")

# åº•éƒ¨ä¿¡æ¯
st.sidebar.markdown("---")
st.sidebar.info("""
**ç³»çµ±ä¿¡æ¯**
- ç‰ˆæœ¬ï¼š2.0.0
- åŠŸèƒ½åˆ†é¡ï¼š10 å¤§é¡
- ç¸½åŠŸèƒ½æ•¸ï¼š66 å€‹
""")

st.sidebar.success("""
**å¿«é€Ÿå‘½ä»¤**
```bash
# é‹è¡Œå›æ¸¬
python3 backtest_multi_timeframe.py

# å¯¦ç›¤äº¤æ˜“
python3 cli.py live --strategy xxx

# åƒæ•¸å„ªåŒ–
python3 cli.py optimize --strategy xxx
```
""")
